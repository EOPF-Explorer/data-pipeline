{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c04e4e9b",
   "metadata": {},
   "source": [
    "# Multi-Resolution Pyramids: Direct Level Access\n",
    "\n",
    "**Demonstrate memory-efficient pyramid access for progressive detail loading.**\n",
    "\n",
    "**Pyramid levels (10980×10980 input):**\n",
    "- Level 0: 10980×10980 @ 10m (920MB)\n",
    "- Level 1: 5490×5490 @ 20m (230MB)  \n",
    "- Level 2: 2745×2745 @ 40m (58MB)\n",
    "- Level 3: 1372×1372 @ 80m (14MB) — **64× smaller**\n",
    "\n",
    "**Learn:** Load specific resolutions, compare sizes, choose optimal levels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc66bd2b",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e9d2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import dask.array as da\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import s3fs\n",
    "import zarr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43c4723",
   "metadata": {},
   "source": [
    "## 2. S3 credentials (K8s secret or env vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e41f9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import credential helper from quickstart\n",
    "import base64\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# Find kubectl (search PATH and common locations)\n",
    "kubectl_locations = [\n",
    "    \"kubectl\",  # Use PATH\n",
    "    \"/opt/homebrew/bin/kubectl\",  # Homebrew Apple Silicon\n",
    "    \"/usr/local/bin/kubectl\",  # Homebrew Intel / Linux\n",
    "    \"/usr/bin/kubectl\",  # System (Linux)\n",
    "    str(Path.home() / \".local/bin/kubectl\"),  # User install (Linux)\n",
    "]\n",
    "kubectl = next((k for k in kubectl_locations if k == \"kubectl\" or Path(k).exists()), \"kubectl\")\n",
    "\n",
    "# Auto-detect kubeconfig (relative to notebook location or environment)\n",
    "kubeconfig_paths = [\n",
    "    Path.cwd().parent / \".work/kubeconfig\",  # Relative: ../work/kubeconfig from notebooks/\n",
    "    Path(os.getenv(\"KUBECONFIG\", \"\")),  # Environment variable\n",
    "    Path.home() / \".kube/config\",  # Default kubectl location\n",
    "]\n",
    "kubeconfig = next((str(p) for p in kubeconfig_paths if p.exists()), None)\n",
    "\n",
    "# Try to fetch from Kubernetes\n",
    "if (not os.getenv(\"AWS_SECRET_ACCESS_KEY\") or not os.getenv(\"AWS_ACCESS_KEY_ID\")) and kubeconfig:\n",
    "    try:\n",
    "        for key in [\"AWS_ACCESS_KEY_ID\", \"AWS_SECRET_ACCESS_KEY\"]:\n",
    "            result = subprocess.run(\n",
    "                [\n",
    "                    kubectl,\n",
    "                    \"get\",\n",
    "                    \"secret\",\n",
    "                    \"geozarr-s3-credentials\",\n",
    "                    \"-n\",\n",
    "                    \"devseed\",\n",
    "                    \"-o\",\n",
    "                    f\"jsonpath={{.data.{key}}}\",\n",
    "                ],\n",
    "                env={\"KUBECONFIG\": kubeconfig},\n",
    "                capture_output=True,\n",
    "                text=True,\n",
    "                timeout=5,\n",
    "            )\n",
    "            if result.returncode == 0 and result.stdout:\n",
    "                os.environ[key] = base64.b64decode(result.stdout).decode()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "if not os.getenv(\"AWS_ENDPOINT_URL\"):\n",
    "    os.environ[\"AWS_ENDPOINT_URL\"] = \"https://s3.de.io.cloud.ovh.net\"\n",
    "\n",
    "# Verify\n",
    "if os.getenv(\"AWS_ACCESS_KEY_ID\") and os.getenv(\"AWS_SECRET_ACCESS_KEY\"):\n",
    "    print(f\"✅ AWS configured: {os.getenv('AWS_ENDPOINT_URL')}\")\n",
    "else:\n",
    "    print(\"❌ Missing AWS credentials! Set AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c71b39e",
   "metadata": {},
   "source": [
    "## 3. Dataset path + S3 filesystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9180e92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 dataset\n",
    "s3_base = \"s3://esa-zarr-sentinel-explorer-fra/tests-output/sentinel-2-l2a/S2B_MSIL2A_20250921T100029_N0511_R122_T33TUG_20250921T135752.zarr\"\n",
    "\n",
    "# Pyramid levels available in this dataset (eopf-geozarr generates 0-3 for 10980×10980 input)\n",
    "LEVELS = [0, 1, 2, 3]  # Full resolution → coarsest overview\n",
    "\n",
    "# S3 filesystem\n",
    "fs = s3fs.S3FileSystem(anon=False, client_kwargs={\"endpoint_url\": os.getenv(\"AWS_ENDPOINT_URL\")})\n",
    "\n",
    "print(f\"✓ Dataset: {s3_base.split('/')[-1]}\")\n",
    "print(f\"✓ Levels to test: {LEVELS}\")\n",
    "print(\"✓ Expected dimensions: [10980, 5490, 2745, 1372] pixels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4fbd46",
   "metadata": {},
   "source": [
    "## 4. Load all levels (0-3) with timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e14a974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store results for each level\n",
    "level_data = {}\n",
    "\n",
    "for level in LEVELS:\n",
    "    print(f\"\\nLoading level {level}...\")\n",
    "\n",
    "    # Load red band\n",
    "    band_path = f\"{s3_base[5:]}/measurements/reflectance/r10m/{level}/b04\"\n",
    "    store = s3fs.S3Map(root=band_path, s3=fs)\n",
    "\n",
    "    # Time the load\n",
    "    start = time.perf_counter()\n",
    "    z_array = zarr.open(store, mode=\"r\")\n",
    "    da_array = da.from_zarr(store)\n",
    "    elapsed = time.perf_counter() - start\n",
    "\n",
    "    # Get metadata\n",
    "    shape = z_array.shape\n",
    "    chunk_size = z_array.chunks\n",
    "    nbytes = np.prod(shape) * 8  # float64\n",
    "\n",
    "    level_data[level] = {\n",
    "        \"shape\": shape,\n",
    "        \"chunks\": chunk_size,\n",
    "        \"size_mb\": nbytes / 1024**2,\n",
    "        \"load_time_ms\": elapsed * 1000,\n",
    "        \"data\": da_array,\n",
    "    }\n",
    "\n",
    "    print(f\"  Shape: {shape}\")\n",
    "    print(f\"  Chunks: {chunk_size}\")\n",
    "    print(f\"  Size: {nbytes / 1024**2:.1f}MB\")\n",
    "    print(f\"  Load time: {elapsed * 1000:.1f}ms\")\n",
    "\n",
    "print(f\"\\n✓ Loaded {len(LEVELS)} pyramid levels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9324782a",
   "metadata": {},
   "source": [
    "## 5. Size comparison (920MB → 14MB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3452e541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data for plotting\n",
    "levels = sorted(level_data.keys())\n",
    "sizes_mb = [level_data[lvl][\"size_mb\"] for lvl in levels]\n",
    "shapes = [f\"{level_data[lvl]['shape'][0]}×{level_data[lvl]['shape'][1]}\" for lvl in levels]\n",
    "\n",
    "# Create bar chart\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "colors = [\"darkred\", \"red\", \"orange\", \"gold\"]\n",
    "bars = ax.bar(range(len(levels)), sizes_mb, color=colors[: len(levels)])\n",
    "\n",
    "ax.set_xlabel(\"Pyramid Level\", fontsize=11)\n",
    "ax.set_ylabel(\"Data Size (MB, uncompressed)\", fontsize=11)\n",
    "ax.set_title(\"GeoZarr Pyramid Size Reduction (Red Band, 10m)\", fontsize=12, fontweight=\"bold\")\n",
    "ax.set_xticks(range(len(levels)))\n",
    "ax.set_xticklabels([f\"Level {lvl}\\n{s}\" for lvl, s in zip(levels, shapes, strict=False)])\n",
    "ax.grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "# Add size labels on bars\n",
    "for _i, (bar, size) in enumerate(zip(bars, sizes_mb, strict=False)):\n",
    "    height = bar.get_height()\n",
    "    ax.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        height,\n",
    "        f\"{size:.1f}MB\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=10,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print size reduction\n",
    "reduction = (1 - sizes_mb[-1] / sizes_mb[0]) * 100\n",
    "ratio = sizes_mb[0] / sizes_mb[-1]\n",
    "print(f\"\\n📊 Size reduction: {reduction:.1f}% (level 0 → level {levels[-1]})\")\n",
    "print(f\"   Ratio: {ratio:.0f}x smaller\")\n",
    "print(f\"   Storage overhead: {(sum(sizes_mb) / sizes_mb[0] - 1) * 100:.0f}% for all pyramid levels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcaaf7b9",
   "metadata": {},
   "source": [
    "## 6. Visual comparison (detail vs file size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb58f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grid of visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 14))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, level in enumerate(LEVELS):\n",
    "    ax = axes[idx]\n",
    "    data = level_data[level][\"data\"].compute()  # Load data from S3\n",
    "\n",
    "    # Normalize for visualization (handle nodata)\n",
    "    data_norm = np.nan_to_num(data, nan=0)\n",
    "    valid_data = data_norm[np.isfinite(data_norm) & (data_norm > 0)]\n",
    "\n",
    "    if len(valid_data) > 0:\n",
    "        p2, p98 = np.percentile(valid_data, [2, 98])\n",
    "        data_stretched = np.clip((data_norm - p2) / (p98 - p2), 0, 1)\n",
    "    else:\n",
    "        data_stretched = data_norm\n",
    "\n",
    "    # Display\n",
    "    im = ax.imshow(data_stretched, cmap=\"RdYlGn\", aspect=\"auto\")\n",
    "\n",
    "    shape = level_data[level][\"shape\"]\n",
    "    size = level_data[level][\"size_mb\"]\n",
    "    resolution = 10 * (2**level)  # Resolution in meters\n",
    "    ax.set_title(\n",
    "        f\"Level {level}: {shape[0]}×{shape[1]} pixels @ {resolution}m\\n{size:.1f}MB uncompressed\",\n",
    "        fontsize=11,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.suptitle(\n",
    "    \"Multi-Resolution Pyramid Visualization (Red Band, B04)\", fontsize=14, fontweight=\"bold\", y=0.98\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Visual comparison complete\")\n",
    "print(\n",
    "    f\"✓ Loaded {sum(level_data[lvl]['size_mb'] for lvl in levels):.1f}MB total across {len(levels)} levels\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e805db",
   "metadata": {},
   "source": [
    "## 7. Use case decision guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a31c682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use case decision matrix\n",
    "use_cases = [\n",
    "    (\"L0: 10980×10980 @ 10m\", \"Scientific analysis, exports, pixel-accurate work\"),\n",
    "    (\"L1: 5490×5490 @ 20m\", \"Regional mapping, high-zoom web maps\"),\n",
    "    (\"L2: 2745×2745 @ 40m\", \"Quick previews, medium-zoom, mobile\"),\n",
    "    (\"L3: 1372×1372 @ 80m\", \"Thumbnails, low-zoom, continental views\"),\n",
    "]\n",
    "\n",
    "print(\"\\n📖 Level Selection Guide:\\n\")\n",
    "for level, use in use_cases:\n",
    "    print(f\"{level}: {use}\")\n",
    "\n",
    "# Performance insights from measurements\n",
    "if level_data:\n",
    "    ratio = level_data[0][\"size_mb\"] / level_data[3][\"size_mb\"]\n",
    "    overhead = (\n",
    "        sum(level_data[lvl][\"size_mb\"] for lvl in level_data) / level_data[0][\"size_mb\"] - 1\n",
    "    ) * 100\n",
    "\n",
    "    print(\"\\n💡 Key Facts:\")\n",
    "    print(f\"  • L3 is {ratio:.0f}× smaller than L0\")\n",
    "    print(f\"  • Total storage: {overhead:.0f}% overhead for all levels\")\n",
    "    print(\"  • Web maps: Auto-select level by zoom (L3→L0 on demand)\")\n",
    "    print(\"  • Tile speedup: 3-5× (see 02_pyramid_performance.ipynb)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded7e22a",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Measured:** 4 pyramid levels (0-3) from S3, 64× size reduction (920MB → 14MB), ~33% total storage overhead\n",
    "\n",
    "**Key insight:** Each level is ¼ the previous (geometric series: 1 + ¼ + 1/16 + 1/64 = 1.33)\n",
    "\n",
    "**Pyramid generation:**\n",
    "```python\n",
    "# eopf-geozarr: create_geozarr_dataset(spatial_chunk=4096, min_dimension=256)\n",
    "# While dimension ≥ 256: downsample 2×, write to /0, /1, /2, /3\n",
    "```\n",
    "\n",
    "**Production value:** \n",
    "- TiTiler auto-selects level by zoom\n",
    "- Progressive loading: level 3 (fast) → level 0 (detailed)\n",
    "- 3-5× tile speedup (see `02_pyramid_performance.ipynb`)\n",
    "\n",
    "**Resources:** [GeoZarr Spec](https://geozarr.github.io) | [TiTiler-EOPF](https://github.com/developmentseed/titiler-eopf) | [STAC API](https://api.explorer.eopf.copernicus.eu/stac)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (data-pipeline)",
   "language": "python",
   "name": "data-pipeline"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
