apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: geozarr-pipeline
  namespace: devseed-staging
spec:
    # Service account with S3 and STAC API permissions
  serviceAccountName: operate-workflow-sa
  entrypoint: main
  # Clean up completed workflows after 24 hours
  ttlStrategy:
    secondsAfterCompletion: 86400  # 24 hours
  # Keep pods on failure for debugging
  podGC:
    strategy: OnWorkflowSuccess
  arguments:
    parameters:
    - name: source_url
    - name: item_id
    - name: register_collection
      value: "sentinel-2-l2a-dp-test"

  templates:
  - name: main
    dag:
      tasks:
      - name: convert
        template: convert-geozarr
      - name: register
        template: register-stac
        dependencies: [convert]
      - name: augment
        template: augment-stac
        dependencies: [register]

  - name: convert-geozarr
    activeDeadlineSeconds: 3600  # 1 hour timeout
    script:
      # Use data-pipeline image with scripts and latest eopf-geozarr
      image: ghcr.io/eopf-explorer/data-pipeline:v21
      imagePullPolicy: Always
      command: [bash]
      source: |
        set -euo pipefail

        SOURCE_URL="{{workflow.parameters.source_url}}"
        COLLECTION="{{workflow.parameters.register_collection}}"
        OUTPUT_PATH="s3://esa-zarr-sentinel-explorer-fra/tests-output/$COLLECTION/{{workflow.parameters.item_id}}.zarr"

        echo "üîç Resolving source..."
        # Check if source is STAC item or direct zarr
        if [[ "$SOURCE_URL" == *"/items/"* ]]; then
          echo "üì° Extracting Zarr URL from STAC item..."
          ZARR_URL=$(python3 /app/scripts/get_zarr_url.py "$SOURCE_URL")
          echo "‚úÖ Zarr URL: $ZARR_URL"
        else
          ZARR_URL="$SOURCE_URL"
          echo "‚úÖ Direct Zarr URL: $ZARR_URL"
        fi

        echo "üöÄ Starting GeoZarr conversion"
        echo "Source: $ZARR_URL"
        echo "Destination: $OUTPUT_PATH"
        echo "Collection: $COLLECTION"

        # Clean up any partial output from previous failed runs
        echo "üßπ Cleaning up any existing output..."
        python3 /app/scripts/cleanup_s3_path.py "$OUTPUT_PATH"

        # S1 requires different parameters (both prod and test collections)
        if [[ "$COLLECTION" == sentinel-1-l1-grd* ]]; then
          ZARR_GROUPS="/measurements"
          EXTRA_FLAGS="--gcp-group /conditions/gcp"
          CHUNK=2048
          echo "üì° S1 GRD mode: groups=$ZARR_GROUPS, chunk=$CHUNK"
        else
          ZARR_GROUPS="/quality/l2a_quicklook/r10m"
          EXTRA_FLAGS="--crs-groups /quality/l2a_quicklook/r10m"
          CHUNK=4096
          echo "üó∫Ô∏è S2 L2A mode: groups=$ZARR_GROUPS, chunk=$CHUNK"
        fi

        # Build conversion command
        eopf-geozarr convert "$ZARR_URL" "$OUTPUT_PATH" \
          --groups "$ZARR_GROUPS" \
          $EXTRA_FLAGS \
          --spatial-chunk $CHUNK \
          --tile-width 512 \
          --verbose
      env:
      - name: PYTHONUNBUFFERED
        value: "1"
      - name: AWS_ACCESS_KEY_ID
        valueFrom:
          secretKeyRef:
            name: geozarr-s3-credentials
            key: AWS_ACCESS_KEY_ID
      - name: AWS_SECRET_ACCESS_KEY
        valueFrom:
          secretKeyRef:
            name: geozarr-s3-credentials
            key: AWS_SECRET_ACCESS_KEY
      - name: AWS_ENDPOINT_URL
        value: "https://s3.de.io.cloud.ovh.net"
      resources:
        requests:
          memory: "8Gi"
          cpu: "1"
        limits:
          memory: "16Gi"
          cpu: "4"

  - name: register-stac
    activeDeadlineSeconds: 300  # 5 min timeout
    container:
      # Use data-pipeline image for Python scripts (register, augment)
      image: ghcr.io/eopf-explorer/data-pipeline:v21
      imagePullPolicy: Always
      command: [python]
      args:
      - /app/scripts/register_stac.py
      - --stac
      - "https://api.explorer.eopf.copernicus.eu/stac"
      - --collection
      - "{{workflow.parameters.register_collection}}"
      - --item-id
      - "{{workflow.parameters.item_id}}"
      - --output
      - "s3://esa-zarr-sentinel-explorer-fra/tests-output/{{workflow.parameters.register_collection}}/{{workflow.parameters.item_id}}.zarr"
      - --src-item
      - "{{workflow.parameters.source_url}}"
      - --s3-endpoint
      - "https://s3.de.io.cloud.ovh.net"
      - --mode
      - "update"
      env:
      - name: PYTHONUNBUFFERED
        value: "1"

  - name: augment-stac
    activeDeadlineSeconds: 300  # 5 min timeout
    container:
      # Use data-pipeline image for Python scripts (register, augment)
      image: ghcr.io/eopf-explorer/data-pipeline:v21
      imagePullPolicy: Always
      command: [python]
      args:
      - /app/scripts/augment_stac_item.py
      - --stac
      - "https://api.explorer.eopf.copernicus.eu/stac"
      - --raster-base
      - "https://api.explorer.eopf.copernicus.eu/raster"
      - --collection
      - "{{workflow.parameters.register_collection}}"
      - --item-id
      - "{{workflow.parameters.item_id}}"
      - --verbose
      env:
      - name: PYTHONUNBUFFERED
        value: "1"

  # Workflow-level metadata to ensure UI visibility
  workflowMetadata:
    labels:
      workflows.argoproj.io/workflow-template: geozarr-pipeline
