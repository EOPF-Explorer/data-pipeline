apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: geozarr-pipeline
  namespace: devseed-staging
spec:
  # Service account with S3 and STAC API permissions
  serviceAccountName: operate-workflow-sa
  entrypoint: main
  # Clean up completed workflows after 24 hours
  ttlStrategy:
    secondsAfterCompletion: 86400  # 24 hours
  # Keep pods on failure for debugging
  podGC:
    strategy: OnWorkflowSuccess
  # Add workflow metadata labels for easier filtering in UI
  workflowMetadata:
    labels:
      workflows.argoproj.io/workflow-template: geozarr-pipeline
      pipeline.eopf/collection: "{{workflow.parameters.register_collection}}"
      pipeline.eopf/item-id: "{{workflow.parameters.item_id}}"
  arguments:
    parameters:
    - name: source_url
    - name: item_id
    - name: register_collection
      value: "sentinel-2-l2a-dp-test"
    - name: stac_api_url
      value: "https://api.explorer.eopf.copernicus.eu/stac"
    - name: raster_api_url
      value: "https://api.explorer.eopf.copernicus.eu/raster"
    - name: s3_endpoint
      value: "https://s3.de.io.cloud.ovh.net"
    - name: s3_output_bucket
      value: "esa-zarr-sentinel-explorer-fra"
    - name: s3_output_prefix
      value: "tests-output"
    - name: pipeline_image_version
      value: "v26"  # v26 includes Dask parallel processing

  templates:
  - name: main
    dag:
      tasks:
      - name: show-parameters
        template: show-parameters
      - name: convert
        template: convert-geozarr
        dependencies: [show-parameters]
      - name: validate
        template: validate
        dependencies: [convert]
      - name: register
        template: register-stac
        dependencies: [validate]
      - name: augment
        template: augment-stac
        dependencies: [register]

  - name: show-parameters
    activeDeadlineSeconds: 60
    script:
      image: ghcr.io/eopf-explorer/data-pipeline:{{workflow.parameters.pipeline_image_version}}
      imagePullPolicy: Always
      command: [bash]
      source: |
        cat <<'EOF'
        â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
        â•‘                         GEOZARR PIPELINE EXECUTION                         â•‘
        â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        ðŸ“‹ WORKFLOW PARAMETERS:
        â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

        ðŸŽ¯ ITEM DETAILS:
          â€¢ Item ID:          {{workflow.parameters.item_id}}
          â€¢ Source URL:       {{workflow.parameters.source_url}}
          â€¢ Collection:       {{workflow.parameters.register_collection}}

        ðŸŒ API ENDPOINTS:
          â€¢ STAC API:         {{workflow.parameters.stac_api_url}}
          â€¢ Raster API:       {{workflow.parameters.raster_api_url}}

        â˜ï¸  S3 CONFIGURATION:
          â€¢ Endpoint:         {{workflow.parameters.s3_endpoint}}
          â€¢ Bucket:           {{workflow.parameters.s3_output_bucket}}
          â€¢ Prefix:           {{workflow.parameters.s3_output_prefix}}

        ðŸ³ IMAGE VERSION:
          â€¢ Pipeline:         {{workflow.parameters.pipeline_image_version}}

        ðŸ“¦ OUTPUT PATH:
          s3://{{workflow.parameters.s3_output_bucket}}/{{workflow.parameters.s3_output_prefix}}/{{workflow.parameters.register_collection}}/{{workflow.parameters.item_id}}.zarr

        â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        â±ï¸  Started: $(date -u +"%Y-%m-%d %H:%M:%S UTC")
        â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        EOF
      env:
      - name: PYTHONUNBUFFERED
        value: "1"

  - name: convert-geozarr
    activeDeadlineSeconds: 3600  # 1 hour timeout
    script:
      image: ghcr.io/eopf-explorer/data-pipeline:{{workflow.parameters.pipeline_image_version}}
      imagePullPolicy: Always
      command: [bash]
      source: |
        set -euo pipefail

        echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        echo "  STEP 1/4: GEOZARR CONVERSION"
        echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        echo ""

        SOURCE_URL="{{workflow.parameters.source_url}}"
        COLLECTION="{{workflow.parameters.register_collection}}"
        OUTPUT_PATH="s3://{{workflow.parameters.s3_output_bucket}}/{{workflow.parameters.s3_output_prefix}}/$COLLECTION/{{workflow.parameters.item_id}}.zarr"

        echo "ðŸ” [1/6] Resolving source..."
        # Check if source is STAC item or direct zarr
        if [[ "$SOURCE_URL" == *"/items/"* ]]; then
          echo "ðŸ“¡ Extracting Zarr URL from STAC item..."
          ZARR_URL=$(python3 /app/scripts/get_zarr_url.py "$SOURCE_URL")
          echo "âœ… Zarr URL: $ZARR_URL"
        else
          ZARR_URL="$SOURCE_URL"
          echo "âœ… Direct Zarr URL: $ZARR_URL"
        fi
        echo ""

        echo "ï¿½ [2/6] Getting conversion parameters for $COLLECTION..."
        eval $(python3 /app/scripts/get_conversion_params.py --collection "$COLLECTION")
        echo "   Groups:      $ZARR_GROUPS"
        echo "   Chunk:       $CHUNK"
        echo "   Tile width:  $TILE_WIDTH"
        echo "   Extra flags: $EXTRA_FLAGS"
        echo ""

        echo "ðŸ§¹ [3/6] Cleaning up existing output..."
        if [ -f /app/scripts/cleanup_s3_path.py ]; then
          python3 /app/scripts/cleanup_s3_path.py "$OUTPUT_PATH" || echo "âš ï¸  Cleanup failed (may not exist yet)"
        else
          echo "â„¹ï¸  Skipping cleanup (script not available)"
        fi
        echo ""

        echo "ðŸš€ [4/6] Starting GeoZarr conversion..."
        echo "   Source:      $ZARR_URL"
        echo "   Destination: $OUTPUT_PATH"
        echo "   Collection:  $COLLECTION"
        echo ""
        echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
        echo "  CONVERSION LOGS (this may take 10-30 minutes for large datasets)"
        echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
        echo ""

        # Build conversion command with Dask for parallel processing
        eopf-geozarr convert "$ZARR_URL" "$OUTPUT_PATH" \
          --groups "$ZARR_GROUPS" \
          $EXTRA_FLAGS \
          --spatial-chunk $CHUNK \
          --tile-width $TILE_WIDTH \
          --dask-cluster \
          --verbose

        echo ""
        echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
        echo "âœ… [6/6] Conversion completed successfully!"
        echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
      env:
      - name: PYTHONUNBUFFERED
        value: "1"
      - name: AWS_ACCESS_KEY_ID
        valueFrom:
          secretKeyRef:
            name: geozarr-s3-credentials
            key: AWS_ACCESS_KEY_ID
      - name: AWS_SECRET_ACCESS_KEY
        valueFrom:
          secretKeyRef:
            name: geozarr-s3-credentials
            key: AWS_SECRET_ACCESS_KEY
      - name: AWS_ENDPOINT_URL
        value: "{{workflow.parameters.s3_endpoint}}"
      resources:
        requests:
          memory: "8Gi"
          cpu: "1"
        limits:
          memory: "16Gi"
          cpu: "4"

  - name: validate
    activeDeadlineSeconds: 300  # 5 min timeout
    script:
      image: ghcr.io/eopf-explorer/data-pipeline:{{workflow.parameters.pipeline_image_version}}
      imagePullPolicy: Always
      command: [bash]
      source: |
        set -euo pipefail

        echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        echo "  STEP 2/4: GEOZARR VALIDATION"
        echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        echo ""
        echo "ðŸ” Validating GeoZarr structure and compliance..."
        echo ""

        python /app/scripts/validate_geozarr.py \
          "s3://{{workflow.parameters.s3_output_bucket}}/{{workflow.parameters.s3_output_prefix}}/{{workflow.parameters.register_collection}}/{{workflow.parameters.item_id}}.zarr" \
          --item-id "{{workflow.parameters.item_id}}" \
          --verbose

        echo ""
        echo "âœ… Validation completed successfully!"
      env:
      - name: PYTHONUNBUFFERED
        value: "1"
      - name: AWS_ACCESS_KEY_ID
        valueFrom:
          secretKeyRef:
            name: geozarr-s3-credentials
            key: AWS_ACCESS_KEY_ID
      - name: AWS_SECRET_ACCESS_KEY
        valueFrom:
          secretKeyRef:
            name: geozarr-s3-credentials
            key: AWS_SECRET_ACCESS_KEY
      - name: AWS_ENDPOINT_URL
        value: "{{workflow.parameters.s3_endpoint}}"
      - name: ZARR_V3_EXPERIMENTAL_API
        value: "1"
      resources:
        requests:
          memory: "2Gi"
        limits:
          memory: "4Gi"

  - name: register-stac
    activeDeadlineSeconds: 300  # 5 min timeout
    script:
      image: ghcr.io/eopf-explorer/data-pipeline:{{workflow.parameters.pipeline_image_version}}
      imagePullPolicy: Always
      command: [bash]
      source: |
        set -euo pipefail

        echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        echo "  STEP 3/4: STAC REGISTRATION"
        echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        echo ""
        echo "ðŸ“ Registering item in STAC API..."
        echo "   Collection: {{workflow.parameters.register_collection}}"
        echo "   Item ID:    {{workflow.parameters.item_id}}"
        echo "   STAC API:   {{workflow.parameters.stac_api_url}}"
        echo ""

        python /app/scripts/register_stac.py \
          --stac "{{workflow.parameters.stac_api_url}}" \
          --collection "{{workflow.parameters.register_collection}}" \
          --item-id "{{workflow.parameters.item_id}}" \
          --output "s3://{{workflow.parameters.s3_output_bucket}}/{{workflow.parameters.s3_output_prefix}}/{{workflow.parameters.register_collection}}/{{workflow.parameters.item_id}}.zarr" \
          --src-item "{{workflow.parameters.source_url}}" \
          --s3-endpoint "{{workflow.parameters.s3_endpoint}}" \
          --mode "update"

        echo ""
        echo "âœ… Registration completed successfully!"
      env:
      - name: PYTHONUNBUFFERED
        value: "1"

  - name: augment-stac
    activeDeadlineSeconds: 300  # 5 min timeout
    script:
      image: ghcr.io/eopf-explorer/data-pipeline:{{workflow.parameters.pipeline_image_version}}
      imagePullPolicy: Always
      command: [bash]
      source: |
        set -euo pipefail

        echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        echo "  STEP 4/4: STAC AUGMENTATION"
        echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        echo ""
        echo "ðŸŽ¨ Adding preview links and metadata to STAC item..."
        echo "   Collection:  {{workflow.parameters.register_collection}}"
        echo "   Item ID:     {{workflow.parameters.item_id}}"
        echo "   Raster API:  {{workflow.parameters.raster_api_url}}"
        echo ""

        python /app/scripts/augment_stac_item.py \
          --stac "{{workflow.parameters.stac_api_url}}" \
          --raster-base "{{workflow.parameters.raster_api_url}}" \
          --collection "{{workflow.parameters.register_collection}}" \
          --item-id "{{workflow.parameters.item_id}}" \
          --verbose

        echo ""
        echo "âœ… Augmentation completed successfully!"
        echo ""
        echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        echo "  ðŸŽ‰ PIPELINE COMPLETED SUCCESSFULLY!"
        echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        echo ""
        echo "ðŸ“ View item in STAC API:"
        echo "   {{workflow.parameters.stac_api_url}}/collections/{{workflow.parameters.register_collection}}/items/{{workflow.parameters.item_id}}"
        echo ""
        echo "ðŸ“¦ GeoZarr output location:"
        echo "   s3://{{workflow.parameters.s3_output_bucket}}/{{workflow.parameters.s3_output_prefix}}/{{workflow.parameters.register_collection}}/{{workflow.parameters.item_id}}.zarr"
        echo ""
      env:
      - name: PYTHONUNBUFFERED
        value: "1"

  # Workflow-level metadata to ensure UI visibility
  workflowMetadata:
    labels:
      workflows.argoproj.io/workflow-template: geozarr-pipeline
