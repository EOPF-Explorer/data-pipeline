{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storage Tier Management Workflow\n",
    "\n",
    "This notebook demonstrates how to use the `change_storage_tier.py` and `update_stac_storage_tier.py` scripts for automated storage tier management.\n",
    "\n",
    "## Purpose\n",
    "\n",
    "These scripts are designed to be integrated into **automated cron workflows** that optimize storage costs by moving older datasets to cheaper storage tiers while keeping metadata synchronized.\n",
    "\n",
    "### Automated Workflow Process:\n",
    "\n",
    "1. **Inspect current storage tier metadata** in STAC items\n",
    "2. **Change S3 object storage classes** based on dataset age and access patterns  \n",
    "3. **Update STAC catalog** with new storage tier information\n",
    "4. **Verify changes** were applied correctly\n",
    "\n",
    "**Use Case**: Implement automated data lifecycle management to reduce storage costs as datasets age, moving from expensive immediate-access storage (STANDARD) to cheaper archive storage (STANDARD_IA) over time.\n",
    "\n",
    "### Background Context\n",
    "\n",
    "This workflow addresses the need for automated storage optimization in large-scale Earth observation data archives:\n",
    "\n",
    "- **Issue #178**: [Storage tier optimization strategy](https://github.com/EOPF-Explorer/coordination/issues/178)\n",
    "- **Issue #182**: [Automated storage class transitions](https://github.com/EOPF-Explorer/coordination/issues/182)\n",
    "\n",
    "## Two-Step Process Overview\n",
    "\n",
    "### Step A: Change S3 Storage Classes\n",
    "Use `change_storage_tier.py` to change the actual storage class of objects in S3.\n",
    "\n",
    "### Step B: Update STAC Metadata  \n",
    "Use `update_stac_storage_tier.py` to update STAC items with current storage tier information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Storage tier utilities imported successfully\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "from pystac import Item\n",
    "from pystac_client import Client\n",
    "\n",
    "# Add scripts directory to path to import storage_tier_utils\n",
    "# Notebook is in: operator-tools/example_notebooks/\n",
    "# Scripts are in: scripts/\n",
    "# So we need to go up 2 levels then into scripts\n",
    "scripts_path = Path.cwd().parent.parent / \"scripts\"\n",
    "sys.path.insert(0, str(scripts_path))\n",
    "\n",
    "try:\n",
    "    import storage_tier_utils  # Import module to verify availability  # noqa: F401\n",
    "\n",
    "    print(\"‚úÖ Storage tier utilities imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è  Could not import storage_tier_utils: {e}\")\n",
    "    print(\"   Make sure you're running from the correct directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration loaded\n",
      "   STAC API:  https://api.explorer.eopf.copernicus.eu/stac\n",
      "   Collection: sentinel-2-l2a-staging\n"
     ]
    }
   ],
   "source": [
    "# STAC API Configuration - using staging collection\n",
    "STAC_API_URL = \"https://api.explorer.eopf.copernicus.eu/stac\"\n",
    "COLLECTION = \"sentinel-2-l2a-staging\"\n",
    "\n",
    "# S3 Configuration (if needed for direct queries)\n",
    "S3_ENDPOINT = \"https://s3.de.io.cloud.ovh.net\"  # Example OVHcloud endpoint\n",
    "\n",
    "print(\"‚úÖ Configuration loaded\")\n",
    "print(f\"   STAC API:  {STAC_API_URL}\")\n",
    "print(f\"   Collection: {COLLECTION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Helper functions loaded\n"
     ]
    }
   ],
   "source": [
    "def extract_storage_tier_info(item: Item) -> dict[str, any]:\n",
    "    \"\"\"\n",
    "    Extract storage tier information from a STAC item's assets.\n",
    "\n",
    "    Args:\n",
    "        item: PySTAC Item object\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with storage tier information per asset\n",
    "    \"\"\"\n",
    "    storage_info = {\"item_id\": item.id, \"assets\": {}}\n",
    "\n",
    "    for asset_key, asset in item.assets.items():\n",
    "        asset_info = {\n",
    "            \"href\": asset.href,\n",
    "            \"storage_tier\": None,\n",
    "            \"has_alternate_s3\": False,\n",
    "            \"storage_tier_distribution\": None,\n",
    "        }\n",
    "\n",
    "        # Check for storage tier in alternate.s3 metadata\n",
    "        if (\n",
    "            hasattr(asset, \"extra_fields\")\n",
    "            and asset.extra_fields\n",
    "            and \"alternate\" in asset.extra_fields\n",
    "        ):\n",
    "            alternate = asset.extra_fields.get(\"alternate\", {})\n",
    "            if isinstance(alternate, dict) and \"s3\" in alternate:\n",
    "                s3_info = alternate.get(\"s3\", {})\n",
    "                if isinstance(s3_info, dict):\n",
    "                    asset_info[\"has_alternate_s3\"] = True\n",
    "\n",
    "                    # Get storage tier\n",
    "                    if \"ovh:storage_tier\" in s3_info:\n",
    "                        asset_info[\"storage_tier\"] = s3_info[\"ovh:storage_tier\"]\n",
    "\n",
    "                    # Get storage tier distribution (for mixed storage)\n",
    "                    if \"ovh:storage_tier_distribution\" in s3_info:\n",
    "                        asset_info[\"storage_tier_distribution\"] = s3_info[\n",
    "                            \"ovh:storage_tier_distribution\"\n",
    "                        ]\n",
    "\n",
    "        storage_info[\"assets\"][asset_key] = asset_info\n",
    "\n",
    "    return storage_info\n",
    "\n",
    "\n",
    "def display_storage_tier_summary(storage_info: dict[str, any]) -> None:\n",
    "    \"\"\"\n",
    "    Display a formatted summary of storage tier information.\n",
    "\n",
    "    Args:\n",
    "        storage_info: Dictionary from extract_storage_tier_info()\n",
    "    \"\"\"\n",
    "    print(f\"\\nüì¶ Item: {storage_info['item_id']}\")\n",
    "    print(f\"   Assets: {len(storage_info['assets'])} total\")\n",
    "\n",
    "    # Count storage tiers\n",
    "    tier_counts = {}\n",
    "    assets_with_tier = 0\n",
    "    assets_with_s3_alternate = 0\n",
    "\n",
    "    for _asset_key, asset_info in storage_info[\"assets\"].items():\n",
    "        if asset_info.get(\"has_alternate_s3\", False):\n",
    "            assets_with_s3_alternate += 1\n",
    "\n",
    "        tier = asset_info.get(\"storage_tier\")\n",
    "        if tier:\n",
    "            assets_with_tier += 1\n",
    "            tier_counts[tier] = tier_counts.get(tier, 0) + 1\n",
    "\n",
    "    # Display summary\n",
    "    print(f\"   Assets with S3 alternate: {assets_with_s3_alternate}/{len(storage_info['assets'])}\")\n",
    "\n",
    "    if assets_with_tier > 0:\n",
    "        print(\n",
    "            f\"   ‚úÖ Assets with storage tier info: {assets_with_tier}/{len(storage_info['assets'])}\"\n",
    "        )\n",
    "        print(\"   Storage tier distribution:\")\n",
    "        for tier, count in sorted(tier_counts.items()):\n",
    "            print(f\"      - {tier}: {count} asset(s)\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è  No storage tier information found in any assets\")\n",
    "\n",
    "\n",
    "def display_detailed_asset_info(storage_info: dict[str, any], max_assets: int = 5) -> None:\n",
    "    \"\"\"\n",
    "    Display detailed storage tier information for each asset.\n",
    "\n",
    "    Args:\n",
    "        storage_info: Dictionary from extract_storage_tier_info()\n",
    "        max_assets: Maximum number of assets to display in detail\n",
    "    \"\"\"\n",
    "    print(f\"\\nüìÑ Detailed Asset Information (showing first {max_assets} assets):\\n\")\n",
    "\n",
    "    for assets_shown, (asset_key, asset_info) in enumerate(storage_info[\"assets\"].items()):\n",
    "        if assets_shown >= max_assets:\n",
    "            remaining = len(storage_info[\"assets\"]) - max_assets\n",
    "            print(f\"\\n   ... and {remaining} more asset(s)\")\n",
    "            break\n",
    "\n",
    "        print(f\"   Asset: {asset_key}\")\n",
    "        print(f\"      Storage Tier: {asset_info.get('storage_tier') or '‚ùå Not set'}\")\n",
    "        print(f\"      Has S3 Alternate: {asset_info.get('has_alternate_s3', False)}\")\n",
    "\n",
    "        # Show distribution if available\n",
    "        distribution = asset_info.get(\"storage_tier_distribution\")\n",
    "        if distribution and isinstance(distribution, dict):\n",
    "            print(f\"      Tier Distribution: {distribution}\")\n",
    "\n",
    "        href = asset_info.get(\"href\", \"\")\n",
    "        if len(href) > 80:\n",
    "            print(f\"      HREF: {href[:80]}...\")\n",
    "        else:\n",
    "            print(f\"      HREF: {href}\")\n",
    "        print()\n",
    "\n",
    "\n",
    "print(\"‚úÖ Helper functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Search for STAC Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Searching for items... \n",
      "   Collection: sentinel-2-l2a-staging\n",
      "   AOI: [-5.14, 41.33, 9.56, 51.09]\n",
      "   Time Range: 2025-07-30T00:00:00Z to 2025-07-31T23:59:59Z\n"
     ]
    }
   ],
   "source": [
    "# Define search parameters\n",
    "# Area of Interest (AOI) - Bounding box: [min_lon, min_lat, max_lon, max_lat]\n",
    "# Example: Rome area\n",
    "# aoi_bbox = [12.4, 41.8, 12.6, 42.0]\n",
    "# Example 2: Majorca area (2.1697998046875004%2C39.21097520599528%2C3.8177490234375004)\n",
    "# aoi_bbox = [2.16, 39.21, 3.82, 39.78]\n",
    "# Example 3: France Full\n",
    "aoi_bbox = [-5.14, 41.33, 9.56, 51.09]\n",
    "# Example 4: Lagoon From Venice to Trieste\n",
    "# aoi_bbox = [12.0, 44.4, 14.0, 46.0]\n",
    "# La Palma Island\n",
    "# aoi_bbox = [-18, 27.4, -13.70, 29.5]\n",
    "# Italy Full\n",
    "# aoi_bbox = [6.627265, 35.492537, 18.513648, 47.092146]\n",
    "# 2025 Corbi√®res Massif wildfire area\n",
    "# aoi_bbox = [2.4, 42.8, 3.2, 43.1]\n",
    "# Pi√≥d√£o, Portugal wildfire area\n",
    "# aoi_bbox = [-7.866, 40.316, -7.633, 40.483]\n",
    "\n",
    "# Time range\n",
    "start_date = \"2025-07-30T00:00:00Z\"\n",
    "end_date = \"2025-07-31T23:59:59Z\"\n",
    "\n",
    "print(\"üîç Searching for items... \")\n",
    "print(f\"   Collection: {COLLECTION}\")\n",
    "print(f\"   AOI: {aoi_bbox}\")\n",
    "print(f\"   Time Range: {start_date} to {end_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó Connecting to STAC API...\n",
      "‚úÖ Connected to: <Client id=eopf-sentinel-explorer>\n",
      "üîç Executing search...\n",
      "üìÑ Processing search results...\n",
      "   Processing page with 10 features...\n",
      "   Processing page with 1 features...\n",
      "\n",
      "üìä Search Results Summary:\n",
      "   Total features found: 11\n",
      "   Deprecated items skipped: 0\n",
      "   Items with errors skipped: 0\n",
      "   ‚úÖ Valid items collected: 11\n",
      "\n",
      "üìã Sample items:\n",
      "  1. S2B_MSIL2A_20250730T113319_N0511_R080_T30UUU_20250730T135754\n",
      "      Has S3 alternate: True\n",
      "  2. S2B_MSIL2A_20250730T113319_N0511_R080_T29UQR_20250730T135754\n",
      "      Has S3 alternate: True\n",
      "  3. S2C_MSIL2A_20250730T104041_N0511_R008_T32TLS_20250730T160714\n",
      "      Has S3 alternate: True\n",
      "  4. S2C_MSIL2A_20250730T104041_N0511_R008_T31UGQ_20250730T160714\n",
      "      Has S3 alternate: True\n",
      "  5. S2C_MSIL2A_20250730T104041_N0511_R008_T31UFS_20250730T160714\n",
      "      Has S3 alternate: True\n"
     ]
    }
   ],
   "source": [
    "# Connect to STAC API and search\n",
    "print(\"üîó Connecting to STAC API...\")\n",
    "catalog = Client.open(STAC_API_URL)\n",
    "print(f\"‚úÖ Connected to: {catalog}\")\n",
    "\n",
    "print(\"üîç Executing search...\")\n",
    "search = catalog.search(\n",
    "    collections=[COLLECTION],\n",
    "    bbox=aoi_bbox,\n",
    "    datetime=f\"{start_date}/{end_date}\",\n",
    "    limit=10,  # Limit to 10 items for demonstration\n",
    ")\n",
    "\n",
    "print(\"üìÑ Processing search results...\")\n",
    "# Collect items\n",
    "items = []\n",
    "total_features = 0\n",
    "skipped_deprecated = 0\n",
    "skipped_errors = 0\n",
    "\n",
    "for page_dict in search.pages_as_dicts():\n",
    "    features_in_page = page_dict.get(\"features\", [])\n",
    "    total_features += len(features_in_page)\n",
    "    print(f\"   Processing page with {len(features_in_page)} features...\")\n",
    "\n",
    "    for feature in features_in_page:\n",
    "        # Skip deprecated items\n",
    "        properties = feature.get(\"properties\", {})\n",
    "        if properties.get(\"deprecated\", False):\n",
    "            skipped_deprecated += 1\n",
    "            continue\n",
    "\n",
    "        # Clean assets with missing href\n",
    "        if \"assets\" in feature:\n",
    "            original_assets = len(feature[\"assets\"])\n",
    "            feature[\"assets\"] = {\n",
    "                key: asset for key, asset in feature[\"assets\"].items() if \"href\" in asset\n",
    "            }\n",
    "            cleaned_assets = len(feature[\"assets\"])\n",
    "            if original_assets != cleaned_assets:\n",
    "                print(\n",
    "                    f\"   Cleaned {original_assets - cleaned_assets} assets without href from {feature.get('id', 'unknown')}\"\n",
    "                )\n",
    "\n",
    "        try:\n",
    "            item = Item.from_dict(feature)\n",
    "            items.append(item)\n",
    "        except Exception as e:\n",
    "            item_id = feature.get(\"id\", \"unknown\")\n",
    "            print(f\"‚ö†Ô∏è  Skipping item {item_id}: {e}\")\n",
    "            skipped_errors += 1\n",
    "            continue\n",
    "\n",
    "print(\"\\nüìä Search Results Summary:\")\n",
    "print(f\"   Total features found: {total_features}\")\n",
    "print(f\"   Deprecated items skipped: {skipped_deprecated}\")\n",
    "print(f\"   Items with errors skipped: {skipped_errors}\")\n",
    "print(f\"   ‚úÖ Valid items collected: {len(items)}\")\n",
    "\n",
    "if items:\n",
    "    print(\"\\nüìã Sample items:\")\n",
    "    for i, item in enumerate(items[:5], 1):\n",
    "        print(f\"  {i}. {item.id}\")\n",
    "        # Check if this item has any alternate.s3 information\n",
    "        has_s3_alternate = False\n",
    "        for _asset_key, asset in item.assets.items():\n",
    "            if (\n",
    "                hasattr(asset, \"extra_fields\")\n",
    "                and \"alternate\" in asset.extra_fields\n",
    "                and \"s3\" in asset.extra_fields.get(\"alternate\", {})\n",
    "            ):\n",
    "                has_s3_alternate = True\n",
    "                break\n",
    "        print(f\"      Has S3 alternate: {has_s3_alternate}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No items found! Check your search parameters:\")\n",
    "    print(f\"   - Collection: {COLLECTION}\")\n",
    "    print(f\"   - Bbox: {aoi_bbox}\")\n",
    "    print(f\"   - Date range: {start_date} to {end_date}\")\n",
    "    print(\"   Try adjusting the date range or bounding box.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Inspect BEFORE - Current Storage Tier Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "BEFORE:  Current Storage Tier Metadata\n",
      "================================================================================\n",
      "\n",
      "üì¶ Item: S2B_MSIL2A_20250730T113319_N0511_R080_T30UUU_20250730T135754\n",
      "   Assets: 5 total\n",
      "   Assets with S3 alternate: 4/5\n",
      "   ‚úÖ Assets with storage tier info: 4/5\n",
      "   Storage tier distribution:\n",
      "      - EXPRESS_ONEZONE: 1 asset(s)\n",
      "      - STANDARD: 3 asset(s)\n",
      "\n",
      "üì¶ Item: S2B_MSIL2A_20250730T113319_N0511_R080_T29UQR_20250730T135754\n",
      "   Assets: 5 total\n",
      "   Assets with S3 alternate: 4/5\n",
      "   ‚ö†Ô∏è  No storage tier information found in any assets\n",
      "\n",
      "üì¶ Item: S2C_MSIL2A_20250730T104041_N0511_R008_T32TLS_20250730T160714\n",
      "   Assets: 5 total\n",
      "   Assets with S3 alternate: 4/5\n",
      "   ‚ö†Ô∏è  No storage tier information found in any assets\n",
      "\n",
      "üì¶ Item: S2C_MSIL2A_20250730T104041_N0511_R008_T31UGQ_20250730T160714\n",
      "   Assets: 5 total\n",
      "   Assets with S3 alternate: 4/5\n",
      "   ‚ö†Ô∏è  No storage tier information found in any assets\n",
      "\n",
      "üì¶ Item: S2C_MSIL2A_20250730T104041_N0511_R008_T31UFS_20250730T160714\n",
      "   Assets: 5 total\n",
      "   Assets with S3 alternate: 4/5\n",
      "   ‚ö†Ô∏è  No storage tier information found in any assets\n",
      "\n",
      "üì¶ Item: S2C_MSIL2A_20250730T104041_N0511_R008_T31UES_20250730T160714\n",
      "   Assets: 5 total\n",
      "   Assets with S3 alternate: 4/5\n",
      "   ‚ö†Ô∏è  No storage tier information found in any assets\n",
      "\n",
      "üì¶ Item: S2C_MSIL2A_20250730T104041_N0511_R008_T31TFM_20250730T160714\n",
      "   Assets: 5 total\n",
      "   Assets with S3 alternate: 4/5\n",
      "   ‚ö†Ô∏è  No storage tier information found in any assets\n",
      "\n",
      "üì¶ Item: S2C_MSIL2A_20250730T104041_N0511_R008_T31TFJ_20250730T160714\n",
      "   Assets: 5 total\n",
      "   Assets with S3 alternate: 4/5\n",
      "   ‚ö†Ô∏è  No storage tier information found in any assets\n",
      "\n",
      "üì¶ Item: S2C_MSIL2A_20250730T104041_N0511_R008_T31TEL_20250730T160714\n",
      "   Assets: 5 total\n",
      "   Assets with S3 alternate: 4/5\n",
      "   ‚ö†Ô∏è  No storage tier information found in any assets\n",
      "\n",
      "üì¶ Item: S2C_MSIL2A_20250730T104041_N0511_R008_T31TDL_20250730T160714\n",
      "   Assets: 5 total\n",
      "   Assets with S3 alternate: 4/5\n",
      "   ‚ö†Ô∏è  No storage tier information found in any assets\n",
      "\n",
      "üì¶ Item: S2C_MSIL2A_20250730T104041_N0511_R008_T31TCF_20250730T160714\n",
      "   Assets: 5 total\n",
      "   Assets with S3 alternate: 4/5\n",
      "   ‚ö†Ô∏è  No storage tier information found in any assets\n",
      "\n",
      "================================================================================\n",
      "üìä Overall Statistics (BEFORE):\n",
      "   Total items analyzed: 11\n",
      "   Items with storage tier metadata: 1/11\n",
      "   Items missing storage tier metadata: 10/11\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Analyze storage tier information for all found items\n",
    "print(\"=\" * 80)\n",
    "print(\"BEFORE:  Current Storage Tier Metadata\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "storage_info_before = []\n",
    "\n",
    "if not items:\n",
    "    print(\"‚ùå No items to analyze! The items list is empty.\")\n",
    "    print(\"   This might happen if:\")\n",
    "    print(\"   1. No items match your search criteria\")\n",
    "    print(\"   2. All items were filtered out (deprecated, errors, etc.)\")\n",
    "    print(\"   3. There was an issue with the STAC API connection\")\n",
    "else:\n",
    "    for item in items:\n",
    "        info = extract_storage_tier_info(item)\n",
    "        storage_info_before.append(info)\n",
    "        display_storage_tier_summary(info)\n",
    "\n",
    "# Overall statistics\n",
    "total_items = len(items)\n",
    "items_with_tier = sum(\n",
    "    1\n",
    "    for info in storage_info_before\n",
    "    if any(asset.get(\"storage_tier\") for asset in info[\"assets\"].values())\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìä Overall Statistics (BEFORE):\")\n",
    "print(f\"   Total items analyzed: {total_items}\")\n",
    "print(f\"   Items with storage tier metadata: {items_with_tier}/{total_items}\")\n",
    "print(f\"   Items missing storage tier metadata: {total_items - items_with_tier}/{total_items}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Display Detailed Asset Information (Sample Item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Detailed View: First Item\n",
      "================================================================================\n",
      "\n",
      "üìÑ Detailed Asset Information (showing first 10 assets):\n",
      "\n",
      "   Asset: AOT_10m\n",
      "      Storage Tier: STANDARD\n",
      "      Has S3 Alternate: True\n",
      "      Tier Distribution: {'STANDARD': 2}\n",
      "      HREF: https://s3.explorer.eopf.copernicus.eu/esa-zarr-sentinel-explorer-fra/tests-outp...\n",
      "\n",
      "   Asset: SCL_20m\n",
      "      Storage Tier: STANDARD\n",
      "      Has S3 Alternate: True\n",
      "      Tier Distribution: {'STANDARD': 2}\n",
      "      HREF: https://s3.explorer.eopf.copernicus.eu/esa-zarr-sentinel-explorer-fra/tests-outp...\n",
      "\n",
      "   Asset: WVP_10m\n",
      "      Storage Tier: STANDARD\n",
      "      Has S3 Alternate: True\n",
      "      Tier Distribution: {'STANDARD': 2}\n",
      "      HREF: https://s3.explorer.eopf.copernicus.eu/esa-zarr-sentinel-explorer-fra/tests-outp...\n",
      "\n",
      "   Asset: thumbnail\n",
      "      Storage Tier: ‚ùå Not set\n",
      "      Has S3 Alternate: False\n",
      "      HREF: https://api.explorer.eopf.copernicus.eu/raster/collections/sentinel-2-l2a-stagin...\n",
      "\n",
      "   Asset: reflectance\n",
      "      Storage Tier: EXPRESS_ONEZONE\n",
      "      Has S3 Alternate: True\n",
      "      Tier Distribution: {'EXPRESS_ONEZONE': 100}\n",
      "      HREF: https://s3.explorer.eopf.copernicus.eu/esa-zarr-sentinel-explorer-fra/tests-outp...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show detailed information for the first item\n",
    "if storage_info_before:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Detailed View: First Item\")\n",
    "    print(\"=\" * 80)\n",
    "    display_detailed_asset_info(storage_info_before[0], max_assets=10)\n",
    "else:\n",
    "    print(\"No items to display\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Change S3 Storage Classes\n",
    "\n",
    "**This is the first step of the two-step process to change storage tiers.**\n",
    "\n",
    "The `change_storage_tier.py` script changes the actual storage class of S3 objects. This affects storage costs and access patterns.\n",
    "\n",
    "### Available Storage Classes:\n",
    "- **STANDARD**: Immediate access, higher cost\n",
    "- **STANDARD_IA**: Archive storage, lower cost, retrieval required\n",
    "- **EXPRESS_ONEZONE**: High-performance, single AZ\n",
    "\n",
    "### Prerequisites:\n",
    "1. AWS credentials configured for S3 access\n",
    "2. STAC item with `alternate.s3` metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ STEP A: Changing S3 Storage Classes\n",
      "==================================================\n",
      "Sample Item: S2B_MSIL2A_20250730T113319_N0511_R080_T30UUU_20250730T135754\n",
      "\n",
      "üí° To change storage class from STANDARD to STANDARD_IA, run:\n",
      "\n",
      "# 1. Preview changes (dry run)\n",
      "uv run python scripts/change_storage_tier.py \\\n",
      "    --stac-item-url \"https://api.explorer.eopf.copernicus.eu/stac/collections/sentinel-2-l2a-staging/items/S2B_MSIL2A_20250730T113319_N0511_R080_T30UUU_20250730T135754\" \\\n",
      "    --storage-class STANDARD_IA \\\n",
      "    --s3-endpoint \"https://s3.de.io.cloud.ovh.net\" \\\n",
      "    --dry-run\n",
      "\n",
      "# 2. Apply changes\n",
      "uv run python scripts/change_storage_tier.py \\\n",
      "    --stac-item-url \"https://api.explorer.eopf.copernicus.eu/stac/collections/sentinel-2-l2a-staging/items/S2B_MSIL2A_20250730T113319_N0511_R080_T30UUU_20250730T135754\" \\\n",
      "    --storage-class STANDARD_IA \\\n",
      "    --s3-endpoint \"https://s3.de.io.cloud.ovh.net\"\n",
      "\n",
      "üìã Optional filtering examples:\n",
      "# Only change reflectance data:\n",
      "# Add: --include-pattern 'measurements/reflectance/*'\n",
      "# Only 60m resolution data:\n",
      "# Add: --include-pattern '*/r60m/*'\n",
      "# Exclude metadata files:\n",
      "# Add: --exclude-pattern '*.zmetadata'\n"
     ]
    }
   ],
   "source": [
    "# STEP A: Change S3 Storage Classes\n",
    "# This step changes the actual storage class of objects in S3\n",
    "\n",
    "if items:\n",
    "    # Get the first item for demonstration\n",
    "    sample_item = items[0]\n",
    "    item_id = sample_item.id\n",
    "\n",
    "    print(\"üîÑ STEP A: Changing S3 Storage Classes\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Sample Item: {item_id}\")\n",
    "    print(\"\")\n",
    "    print(\"üí° To change storage class from STANDARD to STANDARD_IA, run:\")\n",
    "    print(\"\")\n",
    "    print(\"# 1. Preview changes (dry run)\")\n",
    "    print(\"uv run python scripts/change_storage_tier.py \\\\\")\n",
    "    print(\n",
    "        f'    --stac-item-url \"https://api.explorer.eopf.copernicus.eu/stac/collections/{COLLECTION}/items/{item_id}\" \\\\'\n",
    "    )\n",
    "    print(\"    --storage-class STANDARD_IA \\\\\")\n",
    "    print(f'    --s3-endpoint \"{S3_ENDPOINT}\" \\\\')\n",
    "    print(\"    --dry-run\")\n",
    "    print(\"\")\n",
    "    print(\"# 2. Apply changes\")\n",
    "    print(\"uv run python scripts/change_storage_tier.py \\\\\")\n",
    "    print(\n",
    "        f'    --stac-item-url \"https://api.explorer.eopf.copernicus.eu/stac/collections/{COLLECTION}/items/{item_id}\" \\\\'\n",
    "    )\n",
    "    print(\"    --storage-class STANDARD_IA \\\\\")\n",
    "    print(f'    --s3-endpoint \"{S3_ENDPOINT}\"')\n",
    "    print(\"\")\n",
    "    print(\"üìã Optional filtering examples:\")\n",
    "    print(\"# Only change reflectance data:\")\n",
    "    print(\"# Add: --include-pattern 'measurements/reflectance/*'\")\n",
    "    print(\"# Only 60m resolution data:\")\n",
    "    print(\"# Add: --include-pattern '*/r60m/*'\")\n",
    "    print(\"# Exclude metadata files:\")\n",
    "    print(\"# Add: --exclude-pattern '*.zmetadata'\")\n",
    "else:\n",
    "    print(\"‚ùå No items available for demonstration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Update STAC Catalog Metadata\n",
    "\n",
    "**This is the second step of the two-step process.**\n",
    "\n",
    "After changing S3 storage classes, update the STAC catalog to reflect the current storage tier information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù STEP B: Updating STAC Catalog Metadata\n",
      "==================================================\n",
      "Sample Item: S2B_MSIL2A_20250730T113319_N0511_R080_T30UUU_20250730T135754\n",
      "\n",
      "üí° To update STAC catalog with current storage tier information, run:\n",
      "\n",
      "# 1. Preview changes (dry run)\n",
      "uv run python scripts/update_stac_storage_tier.py \\\n",
      "    --stac-item-url \"https://api.explorer.eopf.copernicus.eu/stac/collections/sentinel-2-l2a-staging/items/S2B_MSIL2A_20250730T113319_N0511_R080_T30UUU_20250730T135754\" \\\n",
      "    --stac-api-url \"https://api.explorer.eopf.copernicus.eu/stac\" \\\n",
      "    --s3-endpoint \"https://s3.de.io.cloud.ovh.net\" \\\n",
      "    --dry-run\n",
      "\n",
      "# 2. Apply updates\n",
      "uv run python scripts/update_stac_storage_tier.py \\\n",
      "    --stac-item-url \"https://api.explorer.eopf.copernicus.eu/stac/collections/sentinel-2-l2a-staging/items/S2B_MSIL2A_20250730T113319_N0511_R080_T30UUU_20250730T135754\" \\\n",
      "    --stac-api-url \"https://api.explorer.eopf.copernicus.eu/stac\" \\\n",
      "    --s3-endpoint \"https://s3.de.io.cloud.ovh.net\"\n",
      "\n",
      "üìã For legacy items without alternate.s3 metadata:\n",
      "# Add: --add-missing\n",
      "\n",
      "‚ÑπÔ∏è  This script will:\n",
      "   - Query S3 for current storage classes\n",
      "   - Update 'ovh:storage_tier' field in alternate.s3\n",
      "   - Handle Zarr directories with mixed storage classes\n",
      "   - Add storage tier distribution for mixed storage\n"
     ]
    }
   ],
   "source": [
    "# STEP B: Update STAC Catalog with Storage Tier Information\n",
    "# This step updates the STAC catalog with current storage tier metadata\n",
    "\n",
    "if items:\n",
    "    sample_item = items[0]\n",
    "    item_id = sample_item.id\n",
    "\n",
    "    print(\"üìù STEP B: Updating STAC Catalog Metadata\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Sample Item: {item_id}\")\n",
    "    print(\"\")\n",
    "    print(\"üí° To update STAC catalog with current storage tier information, run:\")\n",
    "    print(\"\")\n",
    "    print(\"# 1. Preview changes (dry run)\")\n",
    "    print(\"uv run python scripts/update_stac_storage_tier.py \\\\\")\n",
    "    print(\n",
    "        f'    --stac-item-url \"https://api.explorer.eopf.copernicus.eu/stac/collections/{COLLECTION}/items/{item_id}\" \\\\'\n",
    "    )\n",
    "    print(f'    --stac-api-url \"{STAC_API_URL}\" \\\\')\n",
    "    print(f'    --s3-endpoint \"{S3_ENDPOINT}\" \\\\')\n",
    "    print(\"    --dry-run\")\n",
    "    print(\"\")\n",
    "    print(\"# 2. Apply updates\")\n",
    "    print(\"uv run python scripts/update_stac_storage_tier.py \\\\\")\n",
    "    print(\n",
    "        f'    --stac-item-url \"https://api.explorer.eopf.copernicus.eu/stac/collections/{COLLECTION}/items/{item_id}\" \\\\'\n",
    "    )\n",
    "    print(f'    --stac-api-url \"{STAC_API_URL}\" \\\\')\n",
    "    print(f'    --s3-endpoint \"{S3_ENDPOINT}\"')\n",
    "    print(\"\")\n",
    "    print(\"üìã For legacy items without alternate.s3 metadata:\")\n",
    "    print(\"# Add: --add-missing\")\n",
    "    print(\"\")\n",
    "    print(\"‚ÑπÔ∏è  This script will:\")\n",
    "    print(\"   - Query S3 for current storage classes\")\n",
    "    print(\"   - Update 'ovh:storage_tier' field in alternate.s3\")\n",
    "    print(\"   - Handle Zarr directories with mixed storage classes\")\n",
    "    print(\"   - Add storage tier distribution for mixed storage\")\n",
    "else:\n",
    "    print(\"‚ùå No items available for demonstration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Verify Changes\n",
    "\n",
    "After completing both steps, re-run the analysis to confirm changes were applied.\n",
    "\n",
    "**Verify that both storage class changes and STAC updates were successful.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "VERIFICATION: Current Storage Tier Metadata (After Changes)\n",
      "================================================================================\n",
      "\n",
      "üìã To verify changes were applied, re-run the STAC search and analysis:\n",
      "   1. Re-execute the search cell to fetch fresh data\n",
      "   2. Re-run this analysis to see updated storage tier metadata\n",
      "\n",
      "üîÑ For immediate verification, you could also run:\n",
      "   # Check storage tier metadata in STAC:\n",
      "   curl \"https://api.explorer.eopf.copernicus.eu/stac/collections/sentinel-2-l2a-staging/items/S2B_MSIL2A_20250730T113319_N0511_R080_T30UUU_20250730T135754\" | jq \".assets[].alternate.s3.\"ovh:storage_tier\"\"\n",
      "   \n",
      "   # Check actual S3 storage classes:\n",
      "   aws s3api list-objects-v2 --bucket BUCKET --prefix PREFIX --query \"Contents[0:5].[Key,StorageClass]\"\n",
      "\n",
      "\n",
      "üì¶ Item: S2B_MSIL2A_20250730T113319_N0511_R080_T30UUU_20250730T135754\n",
      "   Assets: 5 total\n",
      "   Assets with S3 alternate: 4/5\n",
      "   ‚úÖ Assets with storage tier info: 4/5\n",
      "   Storage tier distribution:\n",
      "      - EXPRESS_ONEZONE: 1 asset(s)\n",
      "      - STANDARD: 3 asset(s)\n",
      "\n",
      "üì¶ Item: S2B_MSIL2A_20250730T113319_N0511_R080_T29UQR_20250730T135754\n",
      "   Assets: 5 total\n",
      "   Assets with S3 alternate: 4/5\n",
      "   ‚ö†Ô∏è  No storage tier information found in any assets\n",
      "\n",
      "üì¶ Item: S2C_MSIL2A_20250730T104041_N0511_R008_T32TLS_20250730T160714\n",
      "   Assets: 5 total\n",
      "   Assets with S3 alternate: 4/5\n",
      "   ‚ö†Ô∏è  No storage tier information found in any assets\n",
      "\n",
      "üì¶ Item: S2C_MSIL2A_20250730T104041_N0511_R008_T31UGQ_20250730T160714\n",
      "   Assets: 5 total\n",
      "   Assets with S3 alternate: 4/5\n",
      "   ‚ö†Ô∏è  No storage tier information found in any assets\n",
      "\n",
      "üì¶ Item: S2C_MSIL2A_20250730T104041_N0511_R008_T31UFS_20250730T160714\n",
      "   Assets: 5 total\n",
      "   Assets with S3 alternate: 4/5\n",
      "   ‚ö†Ô∏è  No storage tier information found in any assets\n",
      "\n",
      "üì¶ Item: S2C_MSIL2A_20250730T104041_N0511_R008_T31UES_20250730T160714\n",
      "   Assets: 5 total\n",
      "   Assets with S3 alternate: 4/5\n",
      "   ‚ö†Ô∏è  No storage tier information found in any assets\n",
      "\n",
      "üì¶ Item: S2C_MSIL2A_20250730T104041_N0511_R008_T31TFM_20250730T160714\n",
      "   Assets: 5 total\n",
      "   Assets with S3 alternate: 4/5\n",
      "   ‚ö†Ô∏è  No storage tier information found in any assets\n",
      "\n",
      "üì¶ Item: S2C_MSIL2A_20250730T104041_N0511_R008_T31TFJ_20250730T160714\n",
      "   Assets: 5 total\n",
      "   Assets with S3 alternate: 4/5\n",
      "   ‚ö†Ô∏è  No storage tier information found in any assets\n",
      "\n",
      "üì¶ Item: S2C_MSIL2A_20250730T104041_N0511_R008_T31TEL_20250730T160714\n",
      "   Assets: 5 total\n",
      "   Assets with S3 alternate: 4/5\n",
      "   ‚ö†Ô∏è  No storage tier information found in any assets\n",
      "\n",
      "üì¶ Item: S2C_MSIL2A_20250730T104041_N0511_R008_T31TDL_20250730T160714\n",
      "   Assets: 5 total\n",
      "   Assets with S3 alternate: 4/5\n",
      "   ‚ö†Ô∏è  No storage tier information found in any assets\n",
      "\n",
      "üì¶ Item: S2C_MSIL2A_20250730T104041_N0511_R008_T31TCF_20250730T160714\n",
      "   Assets: 5 total\n",
      "   Assets with S3 alternate: 4/5\n",
      "   ‚ö†Ô∏è  No storage tier information found in any assets\n",
      "\n",
      "================================================================================\n",
      "üìä Verification Statistics:\n",
      "   Total items analyzed: 11\n",
      "   Items with storage tier metadata: 1/11\n",
      "   Items missing storage tier metadata: 10/11\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Re-fetch and analyze the same items to verify changes\n",
    "print(\"=\" * 80)\n",
    "print(\"VERIFICATION: Current Storage Tier Metadata (After Changes)\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\")\n",
    "print(\"üìã To verify changes were applied, re-run the STAC search and analysis:\")\n",
    "print(\"   1. Re-execute the search cell to fetch fresh data\")\n",
    "print(\"   2. Re-run this analysis to see updated storage tier metadata\")\n",
    "print(\"\")\n",
    "print(\"üîÑ For immediate verification, you could also run:\")\n",
    "if items:\n",
    "    sample_item = items[0]\n",
    "    item_id = sample_item.id\n",
    "    print(\"   # Check storage tier metadata in STAC:\")\n",
    "    print(\n",
    "        f'   curl \"https://api.explorer.eopf.copernicus.eu/stac/collections/{COLLECTION}/items/{item_id}\" | jq \".assets[].alternate.s3.\"ovh:storage_tier\"\"'\n",
    "    )\n",
    "    print(\"   \")\n",
    "    print(\"   # Check actual S3 storage classes:\")\n",
    "    print(\n",
    "        '   aws s3api list-objects-v2 --bucket BUCKET --prefix PREFIX --query \"Contents[0:5].[Key,StorageClass]\"'\n",
    "    )\n",
    "print(\"\")\n",
    "\n",
    "# For demonstration, we'll re-analyze the current items\n",
    "storage_info_verification = []\n",
    "\n",
    "for item in items:\n",
    "    info = extract_storage_tier_info(item)\n",
    "    storage_info_verification.append(info)\n",
    "    display_storage_tier_summary(info)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "# Overall statistics\n",
    "total_items = len(items)\n",
    "items_with_tier_verification = sum(\n",
    "    1\n",
    "    for info in storage_info_verification\n",
    "    if any(asset.get(\"storage_tier\") for asset in info[\"assets\"].values())\n",
    ")\n",
    "\n",
    "print(\"üìä Verification Statistics:\")\n",
    "print(f\"   Total items analyzed: {total_items}\")\n",
    "print(f\"   Items with storage tier metadata: {items_with_tier_verification}/{total_items}\")\n",
    "print(\n",
    "    f\"   Items missing storage tier metadata: {total_items - items_with_tier_verification}/{total_items}\"\n",
    ")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Compare Before vs After"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìä WORKFLOW COMPARISON TEMPLATE\n",
      "================================================================================\n",
      "\n",
      "This section shows how to compare results before and after the workflow.\n",
      "To see actual before/after comparison:\n",
      "\n",
      "1. üîç BEFORE: Run this notebook to capture initial state\n",
      "2. üîÑ EXECUTE: Run both change_storage_tier.py and update_stac_storage_tier.py\n",
      "3. üîç AFTER: Re-run this notebook to see updated state\n",
      "\n",
      "üìã Current Analysis Summary:\n",
      "   Total items analyzed: 11\n",
      "   Items with storage tier metadata: 1/11\n",
      "\n",
      "üìà Cost Optimization Opportunities:\n",
      "   - Items already have storage tier metadata: 1\n",
      "   - Ready for storage class optimization\n",
      "   - Can use filtering to target specific data types\n",
      "\n",
      "üí° Example Workflow for Item: S2B_MSIL2A_20250730T113319_N0511_R080_T30UUU_20250730T135754\n",
      "   # Step A: Change storage classes\n",
      "   uv run python scripts/change_storage_tier.py \\\n",
      "       --stac-item-url \".../items/S2B_MSIL2A_20250730T113319_N0511_R080_T30UUU_20250730T135754\" \\\n",
      "       --storage-class STANDARD_IA --dry-run\n",
      "\n",
      "   # Step B: Update STAC metadata\n",
      "   uv run python scripts/update_stac_storage_tier.py \\\n",
      "       --stac-item-url \".../items/S2B_MSIL2A_20250730T113319_N0511_R080_T30UUU_20250730T135754\" \\\n",
      "       --stac-api-url \"https://api.explorer.eopf.copernicus.eu/stac\" \\\n",
      "       --s3-endpoint \"https://s3.de.io.cloud.ovh.net\"\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# COMPARISON: Before vs After Workflow\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìä WORKFLOW COMPARISON TEMPLATE\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\")\n",
    "print(\"This section shows how to compare results before and after the workflow.\")\n",
    "print(\"To see actual before/after comparison:\")\n",
    "print(\"\")\n",
    "print(\"1. üîç BEFORE: Run this notebook to capture initial state\")\n",
    "print(\"2. üîÑ EXECUTE: Run both change_storage_tier.py and update_stac_storage_tier.py\")\n",
    "print(\"3. üîç AFTER: Re-run this notebook to see updated state\")\n",
    "print(\"\")\n",
    "\n",
    "if storage_info_before:\n",
    "    print(\"üìã Current Analysis Summary:\")\n",
    "    print(f\"   Total items analyzed: {total_items}\")\n",
    "    print(f\"   Items with storage tier metadata: {items_with_tier}/{total_items}\")\n",
    "\n",
    "    if items_with_tier > 0:\n",
    "        print(\"\\nüìà Cost Optimization Opportunities:\")\n",
    "        print(f\"   - Items already have storage tier metadata: {items_with_tier}\")\n",
    "        print(\"   - Ready for storage class optimization\")\n",
    "        print(\"   - Can use filtering to target specific data types\")\n",
    "    else:\n",
    "        print(\"\\n‚öôÔ∏è  Setup Required:\")\n",
    "        print(\"   - No storage tier metadata found\")\n",
    "        print(\"   - Need to run update_stac_storage_tier.py first\")\n",
    "        print(\"   - Use --add-missing flag for legacy items\")\n",
    "\n",
    "    # Show example workflow for first item\n",
    "    if items:\n",
    "        sample_item = items[0]\n",
    "        print(f\"\\nüí° Example Workflow for Item: {sample_item.id}\")\n",
    "        print(\"   # Step A: Change storage classes\")\n",
    "        print(\"   uv run python scripts/change_storage_tier.py \\\\\")\n",
    "        print(f'       --stac-item-url \".../items/{sample_item.id}\" \\\\')\n",
    "        print(\"       --storage-class STANDARD_IA --dry-run\")\n",
    "        print(\"\")\n",
    "        print(\"   # Step B: Update STAC metadata\")\n",
    "        print(\"   uv run python scripts/update_stac_storage_tier.py \\\\\")\n",
    "        print(f'       --stac-item-url \".../items/{sample_item.id}\" \\\\')\n",
    "        print(f'       --stac-api-url \"{STAC_API_URL}\" \\\\')\n",
    "        print(f'       --s3-endpoint \"{S3_ENDPOINT}\"')\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Export Sample STAC Item with Storage Tier Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìã Expected STAC Asset Structure (After Updates)\n",
      "================================================================================\n",
      "\n",
      "After running the complete workflow, STAC assets should contain:\n",
      "\n",
      "{\n",
      "  \"href\": \"https://example.com/path/to/asset\",\n",
      "  \"type\": \"application/x-zarr\",\n",
      "  \"roles\": [\n",
      "    \"data\"\n",
      "  ],\n",
      "  \"alternate\": {\n",
      "    \"s3\": {\n",
      "      \"href\": \"s3://bucket/path/to/asset.zarr\",\n",
      "      \"storage:platform\": \"OVHcloud\",\n",
      "      \"storage:region\": \"de\",\n",
      "      \"storage:requester_pays\": false,\n",
      "      \"ovh:storage_tier\": \"STANDARD_IA\",\n",
      "      \"ovh:storage_tier_distribution\": {\n",
      "        \"STANDARD\": 450,\n",
      "        \"STANDARD_IA\": 608\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "üîë Key Fields Explanation:\n",
      "   üìÅ href: Original HTTPS URL to the asset\n",
      "   üóÉÔ∏è  alternate.s3.href: S3 URL for direct access\n",
      "   üè∑Ô∏è  ovh:storage_tier: Current storage class (STANDARD, STANDARD_IA, etc.)\n",
      "   üìä ovh:storage_tier_distribution: File count per tier (for Zarr with mixed storage)\n",
      "   üåç storage:region: OVH Cloud region (de, gra, sbg, etc.)\n",
      "\n",
      "üîç Current Sample Asset Structure for: S2B_MSIL2A_20250730T113319_N0511_R080_T30UUU_20250730T135754\n",
      "\n",
      "Asset: AOT_10m\n",
      "{\n",
      "  \"href\": \"https://s3.explorer.eopf.copernicus.eu/esa-zarr-sentinel-explorer-fra/tests-output/sentinel-2-l2a-staging/S2B_MSIL2A_20250730T113319_N0511_R080_T30UUU_20250730T135754.zarr/quality/atmosphere/r10m/aot\",\n",
      "  \"type\": \"application/vnd+zarr\",\n",
      "  \"roles\": [\n",
      "    \"data\"\n",
      "  ],\n",
      "  \"alternate\": {\n",
      "    \"s3\": {\n",
      "      \"href\": \"s3://esa-zarr-sentinel-explorer-fra/tests-output/sentinel-2-l2a-staging/S2B_MSIL2A_20250730T113319_N0511_R080_T30UUU_20250730T135754.zarr/quality/atmosphere/r10m/aot\",\n",
      "      \"storage:region\": \"de\",\n",
      "      \"ovh:storage_tier\": \"STANDARD\",\n",
      "      \"storage:platform\": \"OVHcloud\",\n",
      "      \"storage:requester_pays\": false,\n",
      "      \"ovh:storage_tier_distribution\": {\n",
      "        \"STANDARD\": 2\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "üí° To add/update storage tier metadata for this item:\n",
      "   uv run python scripts/update_stac_storage_tier.py \\\n",
      "       --stac-item-url \"https://api.explorer.eopf.copernicus.eu/stac/collections/sentinel-2-l2a-staging/items/S2B_MSIL2A_20250730T113319_N0511_R080_T30UUU_20250730T135754\" \\\n",
      "       --stac-api-url \"https://api.explorer.eopf.copernicus.eu/stac\" \\\n",
      "       --s3-endpoint \"https://s3.de.io.cloud.ovh.net\"\n"
     ]
    }
   ],
   "source": [
    "# Expected STAC Item Structure with Storage Tier Metadata\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìã Expected STAC Asset Structure (After Updates)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nAfter running the complete workflow, STAC assets should contain:\")\n",
    "print(\"\")\n",
    "\n",
    "# Show the expected structure\n",
    "expected_structure = {\n",
    "    \"href\": \"https://example.com/path/to/asset\",\n",
    "    \"type\": \"application/x-zarr\",\n",
    "    \"roles\": [\"data\"],\n",
    "    \"alternate\": {\n",
    "        \"s3\": {\n",
    "            \"href\": \"s3://bucket/path/to/asset.zarr\",\n",
    "            \"storage:platform\": \"OVHcloud\",\n",
    "            \"storage:region\": \"de\",\n",
    "            \"storage:requester_pays\": False,\n",
    "            \"ovh:storage_tier\": \"STANDARD_IA\",\n",
    "            \"ovh:storage_tier_distribution\": {\"STANDARD\": 450, \"STANDARD_IA\": 608},\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "print(json.dumps(expected_structure, indent=2))\n",
    "\n",
    "print(\"\\nüîë Key Fields Explanation:\")\n",
    "print(\"   üìÅ href: Original HTTPS URL to the asset\")\n",
    "print(\"   üóÉÔ∏è  alternate.s3.href: S3 URL for direct access\")\n",
    "print(\"   üè∑Ô∏è  ovh:storage_tier: Current storage class (STANDARD, STANDARD_IA, etc.)\")\n",
    "print(\"   üìä ovh:storage_tier_distribution: File count per tier (for Zarr with mixed storage)\")\n",
    "print(\"   üåç storage:region: OVH Cloud region (de, gra, sbg, etc.)\")\n",
    "\n",
    "if items:\n",
    "    sample_item = items[0]\n",
    "    print(f\"\\nüîç Current Sample Asset Structure for: {sample_item.id}\")\n",
    "\n",
    "    if sample_item.assets:\n",
    "        asset_key = list(sample_item.assets.keys())[0]\n",
    "        asset = sample_item.assets[asset_key]\n",
    "\n",
    "        print(f\"\\nAsset: {asset_key}\")\n",
    "\n",
    "        # Create actual representation\n",
    "        actual_structure = {\n",
    "            \"href\": asset.href,\n",
    "            \"type\": asset.media_type,\n",
    "            \"roles\": asset.roles,\n",
    "        }\n",
    "\n",
    "        if (\n",
    "            hasattr(asset, \"extra_fields\")\n",
    "            and asset.extra_fields\n",
    "            and \"alternate\" in asset.extra_fields\n",
    "        ):\n",
    "            actual_structure[\"alternate\"] = asset.extra_fields[\"alternate\"]\n",
    "        else:\n",
    "            actual_structure[\"alternate\"] = \"‚ùå Not present - run update_stac_storage_tier.py\"\n",
    "\n",
    "        print(json.dumps(actual_structure, indent=2))\n",
    "\n",
    "    print(\"\\nüí° To add/update storage tier metadata for this item:\")\n",
    "    print(\"   uv run python scripts/update_stac_storage_tier.py \\\\\")\n",
    "    print(\n",
    "        f'       --stac-item-url \"https://api.explorer.eopf.copernicus.eu/stac/collections/{COLLECTION}/items/{sample_item.id}\" \\\\'\n",
    "    )\n",
    "    print(f'       --stac-api-url \"{STAC_API_URL}\" \\\\')\n",
    "    print(f'       --s3-endpoint \"{S3_ENDPOINT}\"')\n",
    "else:\n",
    "    print(\"\\n‚ùå No items available to show current structure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: Automated Storage Tier Management\n",
    "\n",
    "This notebook demonstrated how to use the storage tier management scripts that are designed for **automated cron workflows**.\n",
    "\n",
    "### üîÑ Production Automation\n",
    "\n",
    "In production, these scripts will be integrated into automated workflows that:\n",
    "\n",
    "1. **Monitor dataset age** and access patterns\n",
    "2. **Automatically trigger storage class changes** based on predefined policies\n",
    "3. **Keep STAC metadata synchronized** with actual S3 storage classes\n",
    "4. **Generate reports** on cost savings and storage optimization\n",
    "\n",
    "### ‚úÖ Manual Workflow (Demonstrated in this Notebook)\n",
    "\n",
    "#### Step 1: Inspect Current State\n",
    "1. Query STAC items from the catalog\n",
    "2. Extract and analyze current storage tier metadata\n",
    "3. Identify optimization opportunities\n",
    "\n",
    "#### Step 2: Change S3 Storage Classes\n",
    "Use `change_storage_tier.py` to modify actual S3 object storage classes:\n",
    "```bash\n",
    "# Preview changes\n",
    "uv run python scripts/change_storage_tier.py \\\n",
    "    --stac-item-url \"STAC_ITEM_URL\" \\\n",
    "    --storage-class STANDARD_IA \\\n",
    "    --dry-run\n",
    "\n",
    "# Apply changes  \n",
    "uv run python scripts/change_storage_tier.py \\\n",
    "    --stac-item-url \"STAC_ITEM_URL\" \\\n",
    "    --storage-class STANDARD_IA\n",
    "```\n",
    "\n",
    "#### Step 3: Update STAC Catalog\n",
    "Use `update_stac_storage_tier.py` to sync STAC metadata with S3:\n",
    "```bash\n",
    "# Preview updates\n",
    "uv run python scripts/update_stac_storage_tier.py \\\n",
    "    --stac-item-url \"STAC_ITEM_URL\" \\\n",
    "    --stac-api-url \"STAC_API_URL\" \\\n",
    "    --s3-endpoint \"S3_ENDPOINT\" \\\n",
    "    --dry-run\n",
    "\n",
    "# Apply updates\n",
    "uv run python scripts/update_stac_storage_tier.py \\\n",
    "    --stac-item-url \"STAC_ITEM_URL\" \\\n",
    "    --stac-api-url \"STAC_API_URL\" \\\n",
    "    --s3-endpoint \"S3_ENDPOINT\"\n",
    "```\n",
    "\n",
    "#### Step 4: Verify Results\n",
    "1. Re-run analysis to confirm changes\n",
    "2. Check storage tier distribution\n",
    "3. Verify cost optimization goals achieved\n",
    "\n",
    "### üéØ Key Benefits of Automation\n",
    "\n",
    "- **Cost Optimization**: Automatic transition of older datasets to cheaper storage tiers\n",
    "- **Hands-off Management**: Reduces manual intervention for large-scale data archives\n",
    "- **Policy-Driven**: Configure rules based on dataset age, access patterns, or other criteria\n",
    "- **Metadata Consistency**: Automated synchronization between S3 and STAC catalog\n",
    "- **Audit Trail**: Complete tracking of storage transitions and cost savings\n",
    "- **Safe Operations**: Dry-run capabilities and validation checks\n",
    "\n",
    "### üîó Integration Context\n",
    "\n",
    "These scripts support the automated data lifecycle management strategy outlined in:\n",
    "\n",
    "- **[Issue #178](https://github.com/EOPF-Explorer/coordination/issues/178)**: Storage tier optimization strategy\n",
    "- **[Issue #182](https://github.com/EOPF-Explorer/coordination/issues/182)**: Automated storage class transitions\n",
    "\n",
    "### üìö Related Documentation\n",
    "\n",
    "- [README_change_storage_tier.md](../scripts/README_change_storage_tier.md) - Detailed usage guide for changing storage classes\n",
    "- [README_update_storage_tier.md](../scripts/README_update_storage_tier.md) - Guide for updating STAC metadata\n",
    "- [storage_tier_utils.py](../scripts/storage_tier_utils.py) - Utility functions for storage operations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
