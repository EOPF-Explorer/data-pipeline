{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STAC Item Search and Submission to Data Pipeline\n",
    "\n",
    "This notebook allows operators to:\n",
    "\n",
    "1. Define an area of interest (AOI) and time range\n",
    "2. Search for STAC items from the EOPF STAC catalog\n",
    "3. Submit selected items to the data pipeline for processing via HTTP webhook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import requests\n",
    "from pystac import Item\n",
    "from pystac_client import Client\n",
    "\n",
    "# Try to load .env file if available\n",
    "# try:\n",
    "#     from dotenv import load_dotenv\n",
    "\n",
    "#     dotenv_path = Path(\".env\")\n",
    "#     if dotenv_path.exists():\n",
    "#         load_dotenv(dotenv_path)\n",
    "#         print(\"‚úÖ Loaded credentials from .env file\")\n",
    "#     else:\n",
    "#         print(\"‚ÑπÔ∏è  No .env file found, will prompt for credentials\")\n",
    "# except ImportError:\n",
    "#     print(\"‚ÑπÔ∏è  python-dotenv not installed, will prompt for credentials\")\n",
    "#     print(\"   Install with: pip install python-dotenv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration loaded\n"
     ]
    }
   ],
   "source": [
    "# STAC API Configuration\n",
    "SOURCE_STAC_API_URL = \"https://stac.core.eopf.eodc.eu/\"\n",
    "TARGET_STAC_API_URL = \"https://api.explorer.eopf.copernicus.eu/stac\"\n",
    "\n",
    "# Webhook Configuration\n",
    "WEBHOOK_URL = \"http://localhost:12000/samples\"\n",
    "\n",
    "print(\"‚úÖ Configuration loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Area and Time of Interest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area of Interest: [2.4, 42.8, 3.2, 43.1]\n",
      "Time Range: 2025-07-01T00:00:00Z to 2025-10-31T23:59:59Z\n"
     ]
    }
   ],
   "source": [
    "# Area of Interest (AOI) - Bounding box: [min_lon, min_lat, max_lon, max_lat]\n",
    "# Example: Rome area\n",
    "# aoi_bbox = [12.4, 41.8, 12.6, 42.0]\n",
    "# Example 2: Majorca area (2.1697998046875004%2C39.21097520599528%2C3.8177490234375004)\n",
    "# aoi_bbox = [2.16, 39.21, 3.82, 39.78]\n",
    "# Example 3: France Full\n",
    "# aoi_bbox = [-5.14, 41.33, 9.56, 51.09]\n",
    "# Example 4: Lagoon From Venice to Trieste\n",
    "# aoi_bbox = [12.0, 44.4, 14.0, 46.0]\n",
    "# La Palma Island\n",
    "# aoi_bbox = [-18, 27.4, -13.70, 29.5]\n",
    "# Italy Full\n",
    "# aoi_bbox = [6.627265, 35.492537, 18.513648, 47.092146]\n",
    "# 2025 Corbi√®res Massif wildfire area\n",
    "# aoi_bbox = [2.4, 42.8, 3.2, 43.1]\n",
    "# Pi√≥d√£o, Portugal wildfire area\n",
    "aoi_bbox = [-7.866, 40.316, -7.633, 40.483]\n",
    "\n",
    "# Time range\n",
    "start_date = \"2025-07-01T00:00:00Z\"\n",
    "end_date = \"2025-10-31T23:59:59Z\"\n",
    "\n",
    "print(f\"Area of Interest: {aoi_bbox}\")\n",
    "print(f\"Time Range: {start_date} to {end_date}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Browse Available Collections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìö Available Collections (12 total):\n",
      "\n",
      "  - sentinel-2-l2a\n",
      "    The Sentinel-2 Level-2A Collection 1 product provides orthorectified Surface Reflectance (Bottom-Of-...\n",
      "\n",
      "  - sentinel-3-slstr-l1-rbt\n",
      "    The Sentinel-3 SLSTR Level-1B RBT product provides radiances and brightness temperatures for each pi...\n",
      "\n",
      "  - sentinel-2-l1c\n",
      "    The Sentinel-2 Level-1C product is composed of 110x110 km2 tiles (ortho-images in UTM/WGS84 projecti...\n",
      "\n",
      "  - sentinel-3-olci-l2-lrr\n",
      "    The Sentinel-3 OLCI L2 LRR product provides land and atmospheric geophysical parameters computed for...\n",
      "\n",
      "  - sentinel-3-olci-l2-lfr\n",
      "    The Sentinel-3 OLCI L2 LFR product provides land and atmospheric geophysical parameters computed for...\n",
      "\n",
      "  - sentinel-3-olci-l1-efr\n",
      "    The Sentinel-3 OLCI L1 EFR product provides TOA radiances at full resolution for each pixel in the i...\n",
      "\n",
      "  - sentinel-1-l1-slc\n",
      "    The Sentinel-1 Level-1 Single Look Complex (SLC) products consist of focused SAR data, geo-reference...\n",
      "\n",
      "  - sentinel-1-l1-grd\n",
      "    The Sentinel-1 Level-1 Ground Range Detected (GRD) products consist of focused SAR data that has bee...\n",
      "\n",
      "  - sentinel-1-l2-ocn\n",
      "    The Sentinel-1 Level-2 Ocean (OCN) products for wind, wave and currents applications may contain the...\n",
      "\n",
      "  - sentinel-3-slstr-l2-frp\n",
      "    The Sentinel-3 SLSTR Level-2 FRP product provides global (over land and water) fire radiative power.\n",
      "\n",
      "  - sentinel-3-slstr-l2-lst\n",
      "    The Sentinel-3 SLSTR Level-2 LST product provides land surface temperature.\n",
      "\n",
      "  - sentinel-3-olci-l1-err\n",
      "    The Sentinel-3 OLCI L1 ERR product provides TOA radiances at reduced resolution for each pixel in th...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Connect to STAC API\n",
    "catalog = Client.open(SOURCE_STAC_API_URL)\n",
    "\n",
    "# List available collections\n",
    "collections = list(catalog.get_collections())\n",
    "\n",
    "print(f\"\\nüìö Available Collections ({len(collections)} total):\\n\")\n",
    "for col in collections:\n",
    "    print(f\"  - {col.id}\")\n",
    "    if col.description:\n",
    "        print(\n",
    "            f\"    {col.description[:100]}...\"\n",
    "            if len(col.description) > 100\n",
    "            else f\"    {col.description}\"\n",
    "        )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Collection and Search for Items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Searching collection: sentinel-2-l2a\n",
      "üéØ Target collection for processing: sentinel-2-l2a\n"
     ]
    }
   ],
   "source": [
    "# Choose the source collection to search\n",
    "source_collection = \"sentinel-2-l2a\"  # Change this to your desired collection\n",
    "\n",
    "# Choose the target collection for processing\n",
    "target_collection = \"sentinel-2-l2a\"  # Change this to your target collection\n",
    "\n",
    "print(f\"üîç Searching collection: {source_collection}\")\n",
    "print(f\"üéØ Target collection for processing: {target_collection}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  Skipping deprecated item: S2C_MSIL2A_20251031T105221_N0511_R051_T31TDH_20251031T144221\n",
      "‚ö†Ô∏è  Skipping deprecated item: S2A_MSIL2A_20250930T104041_N0511_R008_T31TEH_20250930T143113\n",
      "‚ö†Ô∏è  Skipping deprecated item: S2A_MSIL2A_20250930T104041_N0511_R008_T31TDH_20250930T143113\n",
      "‚ö†Ô∏è  Skipping deprecated item: S2A_MSIL2A_20250920T103741_N0511_R008_T31TEH_20250920T144020\n",
      "‚ö†Ô∏è  Skipping deprecated item: S2A_MSIL2A_20250920T103741_N0511_R008_T31TDH_20250920T144020\n",
      "‚ö†Ô∏è  Skipping deprecated item: S2C_MSIL2A_20250918T104031_N0511_R008_T31TEH_20250918T161413\n",
      "‚ö†Ô∏è  Skipping deprecated item: S2C_MSIL2A_20250918T104031_N0511_R008_T31TDH_20250918T161413\n",
      "‚ö†Ô∏è  Skipping deprecated item: S2B_MSIL2A_20250916T104619_N0511_R051_T31TDH_20250916T133243\n",
      "‚ö†Ô∏è  Skipping deprecated item: S2A_MSIL2A_20250913T104651_N0511_R051_T31TDH_20250913T161813\n",
      "‚ö†Ô∏è  Skipping deprecated item: S2B_MSIL2A_20250913T103619_N0511_R008_T31TEH_20250913T131830\n",
      "‚ö†Ô∏è  Skipping deprecated item: S2B_MSIL2A_20250913T103619_N0511_R008_T31TDH_20250913T131830\n",
      "‚ö†Ô∏è  Skipping deprecated item: S2C_MSIL2A_20250911T104641_N0511_R051_T31TDH_20250911T143257\n",
      "‚ö†Ô∏è  Skipping deprecated item: S2A_MSIL2A_20250910T104041_N0511_R008_T31TEH_20250910T174015\n",
      "‚ö†Ô∏è  Skipping deprecated item: S2A_MSIL2A_20250910T104041_N0511_R008_T31TDH_20250910T174015\n",
      "‚ö†Ô∏è  Skipping deprecated item: S2B_MSIL2A_20250906T104619_N0511_R051_T31TDH_20250906T131128\n",
      "‚ö†Ô∏è  Skipping deprecated item: S2A_MSIL2A_20250903T105041_N0511_R051_T31TDH_20250903T161814\n",
      "‚ö†Ô∏è  Skipping deprecated item: S2B_MSIL2A_20250903T103619_N0511_R008_T31TEH_20250903T144103\n",
      "‚ö†Ô∏è  Skipping deprecated item: S2B_MSIL2A_20250903T103619_N0511_R008_T31TDH_20250903T144103\n",
      "‚ö†Ô∏è  Skipping deprecated item: S2C_MSIL2A_20250901T105041_N0511_R051_T31TDH_20250901T162120\n",
      "‚ö†Ô∏è  Skipping deprecated item: S2A_MSIL2A_20250831T103701_N0511_R008_T31TEH_20250831T145420\n",
      "‚ö†Ô∏è  Skipping deprecated item: S2A_MSIL2A_20250831T103701_N0511_R008_T31TDH_20250831T145420\n",
      "‚ö†Ô∏è  Skipping deprecated item: S2C_MSIL2A_20250829T104041_N0511_R008_T31TEH_20250829T162415\n",
      "‚ö†Ô∏è  Skipping deprecated item: S2C_MSIL2A_20250829T104041_N0511_R008_T31TDH_20250829T162415\n",
      "‚ö†Ô∏è  Skipping deprecated item: S2A_MSIL2A_20250824T104651_N0511_R051_T31TDH_20250824T145914\n",
      "‚ö†Ô∏è  Skipping deprecated item: S2C_MSIL2A_20250822T105041_N0511_R051_T31TDH_20250822T163215\n",
      "‚ö†Ô∏è  Skipping deprecated item: S2A_MSIL2A_20250821T104041_N0511_R008_T31TEH_20250821T143312\n",
      "‚ö†Ô∏è  Skipping deprecated item: S2A_MSIL2A_20250821T104041_N0511_R008_T31TDH_20250821T143312\n",
      "‚ö†Ô∏è  Skipping deprecated item: S2C_MSIL2A_20250819T104041_N0511_R008_T31TEH_20250819T162815\n",
      "‚ö†Ô∏è  Skipping deprecated item: S2C_MSIL2A_20250819T104041_N0511_R008_T31TDH_20250819T162815\n",
      "‚ö†Ô∏è  Skipping deprecated item: S2A_MSIL2A_20250814T105041_N0511_R051_T31TDH_20250814T145413\n",
      "‚ö†Ô∏è  Skipping deprecated item: S2B_MSIL2A_20250814T103629_N0511_R008_T31TEH_20250814T125902\n",
      "‚ö†Ô∏è  Skipping deprecated item: S2C_MSIL2A_20250812T104641_N0511_R051_T31TDH_20250812T161301\n",
      "‚ö†Ô∏è  Skipping deprecated item: S2A_MSIL2A_20250811T103701_N0511_R008_T31TEH_20250811T173718\n",
      "‚ö†Ô∏è  Skipping deprecated item: S2A_MSIL2A_20250811T103701_N0511_R008_T31TDH_20250811T173718\n",
      "‚ö†Ô∏è  Skipping deprecated item: S2B_MSIL2A_20250807T104619_N0511_R051_T31TDH_20250807T131144\n",
      "‚ö†Ô∏è  Skipping deprecated item: S2A_MSIL2A_20250804T104701_N0511_R051_T31TDH_20250804T161517\n",
      "‚ö†Ô∏è  Skipping deprecated item: S2B_MSIL2A_20250804T103629_N0511_R008_T31TEH_20250804T130722\n",
      "‚ö†Ô∏è  Skipping deprecated item: S2B_MSIL2A_20250804T103629_N0511_R008_T31TDH_20250804T130722\n",
      "‚ö†Ô∏è  Skipping deprecated item: S2C_MSIL2A_20250710T104041_N0511_R008_T31TEH_20250710T160920\n",
      "‚ö†Ô∏è  Skipping deprecated item: S2C_MSIL2A_20250710T104041_N0511_R008_T31TDH_20250710T160920\n",
      "‚ö†Ô∏è  Skipping deprecated item: S2B_MSIL2A_20250708T104629_N0511_R051_T31TDH_20250708T132039\n",
      "‚ö†Ô∏è  Skipping deprecated item: S2A_MSIL2A_20250705T105051_N0511_R051_T31TDH_20250705T155300\n",
      "‚ö†Ô∏è  Skipping deprecated item: S2B_MSIL2A_20250705T103629_N0511_R008_T31TEH_20250705T113540\n",
      "‚ö†Ô∏è  Skipping deprecated item: S2B_MSIL2A_20250705T103629_N0511_R008_T31TDH_20250705T124947\n",
      "‚ö†Ô∏è  Skipping deprecated item: S2B_MSIL2A_20250705T103629_N0511_R008_T31TDH_20250705T113540\n",
      "‚ö†Ô∏è  Skipping deprecated item: S2C_MSIL2A_20250703T105051_N0511_R051_T31TDH_20250703T164117\n",
      "‚ö†Ô∏è  Skipping deprecated item: S2A_MSIL2A_20250702T103701_N0511_R008_T31TEH_20250702T145201\n",
      "‚ö†Ô∏è  Skipping deprecated item: S2A_MSIL2A_20250702T103701_N0511_R008_T31TDH_20250702T145201\n",
      "\n",
      "‚úÖ Found 34 items (after filtering).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Search for items\n",
    "search = catalog.search(\n",
    "    collections=[source_collection],\n",
    "    bbox=aoi_bbox,\n",
    "    datetime=f\"{start_date}/{end_date}\",  # Adjust as needed\n",
    "    limit=200,  # Adjust limit as needed\n",
    ")\n",
    "\n",
    "# Collect items paginated results and clean them (workaround for issue #26)\n",
    "# Use pages_as_dicts() to get raw JSON before PySTAC parsing\n",
    "items = []\n",
    "\n",
    "for page_dict in search.pages_as_dicts():\n",
    "    for feature in page_dict.get(\"features\", []):\n",
    "        # Skip deprecated items\n",
    "        properties = feature.get(\"properties\", {})\n",
    "        if properties.get(\"deprecated\", False):\n",
    "            item_id = feature.get(\"id\", \"unknown\")\n",
    "            print(f\"‚ö†Ô∏è  Skipping deprecated item: {item_id}\")\n",
    "            continue\n",
    "\n",
    "        # Clean assets with missing href before parsing\n",
    "        if \"assets\" in feature:\n",
    "            original_count = len(feature[\"assets\"])\n",
    "            feature[\"assets\"] = {\n",
    "                key: asset for key, asset in feature[\"assets\"].items() if \"href\" in asset\n",
    "            }\n",
    "            removed_count = original_count - len(feature[\"assets\"])\n",
    "            if removed_count > 0:\n",
    "                item_id = feature.get(\"id\", \"unknown\")\n",
    "                # print(f\"‚ö†Ô∏è  Item {item_id}: Removed {removed_count} asset(s) with missing href\")\n",
    "\n",
    "        # Now parse the cleaned item\n",
    "        try:\n",
    "            item = Item.from_dict(feature)\n",
    "            items.append(item)\n",
    "        except Exception as e:\n",
    "            item_id = feature.get(\"id\", \"unknown\")\n",
    "            print(f\"‚ö†Ô∏è  Skipping item {item_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "print(f\"\\n‚úÖ Found {len(items)} items (after filtering).\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit Items to Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_item_exists_in_target(item_id: str, target_collection: str) -> bool:\n",
    "    \"\"\"\n",
    "    Check if a STAC item already exists in the target catalog.\n",
    "\n",
    "    Args:\n",
    "        item_id: The ID of the STAC item to check\n",
    "        target_collection: The target collection to check in\n",
    "\n",
    "    Returns:\n",
    "        True if item exists, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Try to get the specific item\n",
    "        item_url = f\"{TARGET_STAC_API_URL}/collections/{target_collection}/items/{item_id}\"\n",
    "        response = requests.get(item_url)\n",
    "\n",
    "        # If we get a 200 response, the item exists\n",
    "        return response.status_code == 200\n",
    "\n",
    "    except Exception as e:\n",
    "        # If there's any error, assume the item doesn't exist\n",
    "        # This prevents false positives that could skip valid items\n",
    "        print(f\"‚ö†Ô∏è  Error checking if item {item_id} exists: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_item_to_pipeline(item_url: str, target_collection: str) -> bool:\n",
    "    \"\"\"\n",
    "    Submit a single STAC item to the data pipeline via HTTP webhook.\n",
    "\n",
    "    Args:\n",
    "        item_url: The self-link URL of the STAC item\n",
    "        target_collection: The target collection for processing\n",
    "\n",
    "    Returns:\n",
    "        True if successful, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create payload\n",
    "        payload = {\n",
    "            \"source_url\": item_url,\n",
    "            \"collection\": target_collection,\n",
    "            \"action\": \"convert-v1-s2\",  # specify the action to use the V1 S2 trigger\n",
    "        }\n",
    "\n",
    "        # Submit via HTTP webhook endpoint\n",
    "        message = json.dumps(payload)\n",
    "        response = requests.post(\n",
    "            WEBHOOK_URL,\n",
    "            data=message,\n",
    "            headers={\"Content-Type\": \"application/json\"},\n",
    "        )\n",
    "\n",
    "        response.raise_for_status()\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error submitting item: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì§ Processing 34 items...\n",
      "\n",
      "‚úÖ Submitted: S2A_MSIL2A_20251030T104211_N0511_R008_T31TEH_20251030T144716\n",
      "‚úÖ Submitted: S2A_MSIL2A_20251030T104211_N0511_R008_T31TDH_20251030T144716\n",
      "‚úÖ Submitted: S2C_MSIL2A_20251028T104151_N0511_R008_T31TEH_20251028T145122\n",
      "‚úÖ Submitted: S2C_MSIL2A_20251028T104151_N0511_R008_T31TDH_20251028T145122\n",
      "‚úÖ Submitted: S2B_MSIL2A_20251026T105039_N0511_R051_T31TDH_20251026T131435\n",
      "‚úÖ Submitted: S2A_MSIL2A_20251023T105131_N0511_R051_T31TDH_20251023T145710\n",
      "‚úÖ Submitted: S2B_MSIL2A_20251023T104009_N0511_R008_T31TEH_20251023T144134\n",
      "‚úÖ Submitted: S2B_MSIL2A_20251023T104009_N0511_R008_T31TDH_20251023T144134\n",
      "‚úÖ Submitted: S2C_MSIL2A_20251021T105111_N0511_R051_T31TDH_20251021T150514\n",
      "‚úÖ Submitted: S2A_MSIL2A_20251020T104101_N0511_R008_T31TEH_20251020T142609\n",
      "‚úÖ Submitted: S2A_MSIL2A_20251020T104101_N0511_R008_T31TDH_20251020T142609\n",
      "‚úÖ Submitted: S2C_MSIL2A_20251018T104051_N0511_R008_T31TEH_20251018T205314\n",
      "‚úÖ Submitted: S2C_MSIL2A_20251018T104051_N0511_R008_T31TDH_20251018T205314\n",
      "‚úÖ Submitted: S2B_MSIL2A_20251016T104939_N0511_R051_T31TDH_20251016T132655\n",
      "‚úÖ Submitted: S2A_MSIL2A_20251013T105041_N0511_R051_T31TDH_20251013T155220\n",
      "‚úÖ Submitted: S2B_MSIL2A_20251013T103909_N0511_R008_T31TEH_20251013T144901\n",
      "‚úÖ Submitted: S2B_MSIL2A_20251013T103909_N0511_R008_T31TDH_20251013T144901\n",
      "‚úÖ Submitted: S2C_MSIL2A_20251008T103941_N0511_R008_T31TEH_20251008T191959\n",
      "‚úÖ Submitted: S2C_MSIL2A_20251008T103941_N0511_R008_T31TDH_20251008T191959\n",
      "‚úÖ Submitted: S2B_MSIL2A_20251006T104829_N0511_R051_T31TDH_20251006T131209\n",
      "‚úÖ Submitted: S2A_MSIL2A_20251003T104911_N0511_R051_T31TDH_20251003T145905\n",
      "‚úÖ Submitted: S2B_MSIL2A_20251003T103759_N0511_R008_T31TEH_20251003T132348\n",
      "‚úÖ Submitted: S2B_MSIL2A_20251003T103759_N0511_R008_T31TDH_20251003T132348\n",
      "‚úÖ Submitted: S2C_MSIL2A_20251001T104901_N0511_R051_T31TDH_20251001T145613\n",
      "‚úÖ Submitted: S2C_MSIL2A_20250928T103831_N0511_R008_T31TEH_20250928T161815\n",
      "‚úÖ Submitted: S2C_MSIL2A_20250928T103831_N0511_R008_T31TDH_20250928T161815\n",
      "‚úÖ Submitted: S2B_MSIL2A_20250926T104719_N0511_R051_T31TDH_20250926T131329\n",
      "‚úÖ Submitted: S2A_MSIL2A_20250923T105051_N0511_R051_T31TDH_20250923T143816\n",
      "‚úÖ Submitted: S2B_MSIL2A_20250923T103639_N0511_R008_T31TEH_20250923T144103\n",
      "‚úÖ Submitted: S2B_MSIL2A_20250923T103639_N0511_R008_T31TDH_20250923T144103\n",
      "‚úÖ Submitted: S2C_MSIL2A_20250921T104751_N0511_R051_T31TDH_20250921T163315\n",
      "‚è≠Ô∏è  Skipping S2A_MSIL2A_20250725T105051_N0511_R051_T31TDH_20250725T143858: Already exists in target catalog\n",
      "‚è≠Ô∏è  Skipping S2B_MSIL2A_20250725T103629_N0511_R008_T31TEH_20250725T130225: Already exists in target catalog\n",
      "‚è≠Ô∏è  Skipping S2B_MSIL2A_20250725T103629_N0511_R008_T31TDH_20250725T130225: Already exists in target catalog\n",
      "\n",
      "üìä Summary:\n",
      "  - Successfully submitted: 31\n",
      "  - Already existed (skipped): 3\n",
      "  - Failed: 0\n",
      "  - Total processed: 34\n"
     ]
    }
   ],
   "source": [
    "# Submit all found items to the pipeline (skip items already in target catalog)\n",
    "if items:\n",
    "    print(f\"\\nüì§ Processing {len(items)} items...\\n\")\n",
    "\n",
    "    success_count = 0\n",
    "    fail_count = 0\n",
    "    skipped_count = 0\n",
    "\n",
    "    for item in items:\n",
    "        # Check if item already exists in target catalog\n",
    "        if check_item_exists_in_target(item.id, target_collection):\n",
    "            print(f\"‚è≠Ô∏è  Skipping {item.id}: Already exists in target catalog\")\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "\n",
    "        # Get the self link (canonical URL for the item)\n",
    "        item_url = next((link.href for link in item.links if link.rel == \"self\"), None)\n",
    "\n",
    "        if not item_url:\n",
    "            print(f\"‚ö†Ô∏è  Skipping {item.id}: No self link found\")\n",
    "            fail_count += 1\n",
    "            continue\n",
    "\n",
    "        # Submit to pipeline\n",
    "        if submit_item_to_pipeline(item_url, target_collection):\n",
    "            print(f\"‚úÖ Submitted: {item.id}\")\n",
    "            success_count += 1\n",
    "        else:\n",
    "            print(f\"‚ùå Failed: {item.id}\")\n",
    "            fail_count += 1\n",
    "\n",
    "    print(\"\\nüìä Summary:\")\n",
    "    print(f\"  - Successfully submitted: {success_count}\")\n",
    "    print(f\"  - Already existed (skipped): {skipped_count}\")\n",
    "    print(f\"  - Failed: {fail_count}\")\n",
    "    print(f\"  - Total processed: {len(items)}\")\n",
    "else:\n",
    "    print(\"No items to submit.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit Specific Items (Optional)\n",
    "\n",
    "If you want to submit only specific items instead of all found items, you can manually select them:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Submit only specific items by index\n",
    "# Uncomment and modify as needed\n",
    "\n",
    "# selected_indices = [0, 1, 2]  # Select first 3 items\n",
    "#\n",
    "# for idx in selected_indices:\n",
    "#     if idx < len(items):\n",
    "#         item = items[idx]\n",
    "#         item_url = next((link.href for link in item.links if link.rel == \"self\"), None)\n",
    "#\n",
    "#         if item_url:\n",
    "#             if submit_item_to_pipeline(item_url, target_collection):\n",
    "#                 print(f\"‚úÖ Submitted: {item.id}\")\n",
    "#             else:\n",
    "#                 print(f\"‚ùå Failed: {item.id}\")\n",
    "#     else:\n",
    "#         print(f\"‚ö†Ô∏è  Index {idx} out of range\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
