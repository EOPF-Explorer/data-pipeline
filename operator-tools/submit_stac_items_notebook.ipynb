{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STAC Item Search and Submission to Data Pipeline\n",
    "\n",
    "This notebook allows operators to:\n",
    "\n",
    "1. Define an area of interest (AOI) and time range\n",
    "2. Search for STAC items from the EOPF STAC catalog\n",
    "3. Submit selected items to the data pipeline for processing via HTTP webhook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import requests\n",
    "from pystac import Item\n",
    "from pystac_client import Client\n",
    "\n",
    "# Try to load .env file if available\n",
    "# try:\n",
    "#     from dotenv import load_dotenv\n",
    "\n",
    "#     dotenv_path = Path(\".env\")\n",
    "#     if dotenv_path.exists():\n",
    "#         load_dotenv(dotenv_path)\n",
    "#         print(\"‚úÖ Loaded credentials from .env file\")\n",
    "#     else:\n",
    "#         print(\"‚ÑπÔ∏è  No .env file found, will prompt for credentials\")\n",
    "# except ImportError:\n",
    "#     print(\"‚ÑπÔ∏è  python-dotenv not installed, will prompt for credentials\")\n",
    "#     print(\"   Install with: pip install python-dotenv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAC API Configuration\n",
    "SOURCE_STAC_API_URL = \"https://stac.core.eopf.eodc.eu/\"\n",
    "TARGET_STAC_API_URL = \"https://api.explorer.eopf.copernicus.eu/stac\"\n",
    "\n",
    "# Webhook Configuration\n",
    "WEBHOOK_URL = \"http://localhost:12000/samples\"\n",
    "\n",
    "print(\"‚úÖ Configuration loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Area and Time of Interest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Area of Interest (AOI) - Bounding box: [min_lon, min_lat, max_lon, max_lat]\n",
    "# Example: Rome area\n",
    "# aoi_bbox = [12.4, 41.8, 12.6, 42.0]\n",
    "# Example 2: Majorca area (2.1697998046875004%2C39.21097520599528%2C3.8177490234375004)\n",
    "# aoi_bbox = [2.16, 39.21, 3.82, 39.78]\n",
    "# Example 3: France Full\n",
    "# aoi_bbox = [-5.14, 41.33, 9.56, 51.09]\n",
    "# Example 4: Lagoon From Venice to Trieste\n",
    "# aoi_bbox = [12.0, 44.4, 14.0, 46.0]\n",
    "# La Palma Island\n",
    "# aoi_bbox = [-18, 27.4, -13.70, 29.5]\n",
    "# Italy Full\n",
    "aoi_bbox = [6.627265, 35.492537, 18.513648, 47.092146]\n",
    "\n",
    "# Time range\n",
    "start_date = \"2025-01-01T00:00:00Z\"\n",
    "end_date = \"2025-12-31T23:59:59Z\"\n",
    "\n",
    "print(f\"Area of Interest: {aoi_bbox}\")\n",
    "print(f\"Time Range: {start_date} to {end_date}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Browse Available Collections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to STAC API\n",
    "catalog = Client.open(SOURCE_STAC_API_URL)\n",
    "\n",
    "# List available collections\n",
    "collections = list(catalog.get_collections())\n",
    "\n",
    "print(f\"\\nüìö Available Collections ({len(collections)} total):\\n\")\n",
    "for col in collections:\n",
    "    print(f\"  - {col.id}\")\n",
    "    if col.description:\n",
    "        print(\n",
    "            f\"    {col.description[:100]}...\"\n",
    "            if len(col.description) > 100\n",
    "            else f\"    {col.description}\"\n",
    "        )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Collection and Search for Items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the source collection to search\n",
    "source_collection = \"sentinel-2-l2a\"  # Change this to your desired collection\n",
    "\n",
    "# Choose the target collection for processing\n",
    "target_collection = \"sentinel-2-l2a\"  # Change this to your target collection\n",
    "\n",
    "print(f\"üîç Searching collection: {source_collection}\")\n",
    "print(f\"üéØ Target collection for processing: {target_collection}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for items\n",
    "search = catalog.search(\n",
    "    collections=[source_collection],\n",
    "    bbox=aoi_bbox,\n",
    "    datetime=f\"{start_date}/{end_date}\",  # Adjust as needed\n",
    "    limit=200,  # Adjust limit as needed\n",
    ")\n",
    "\n",
    "# Collect items paginated results and clean them (workaround for issue #26)\n",
    "# Use pages_as_dicts() to get raw JSON before PySTAC parsing\n",
    "items = []\n",
    "\n",
    "for page_dict in search.pages_as_dicts():\n",
    "    for feature in page_dict.get(\"features\", []):\n",
    "        # Skip deprecated items\n",
    "        properties = feature.get(\"properties\", {})\n",
    "        if properties.get(\"deprecated\", False):\n",
    "            item_id = feature.get(\"id\", \"unknown\")\n",
    "            print(f\"‚ö†Ô∏è  Skipping deprecated item: {item_id}\")\n",
    "            continue\n",
    "\n",
    "        # Clean assets with missing href before parsing\n",
    "        if \"assets\" in feature:\n",
    "            original_count = len(feature[\"assets\"])\n",
    "            feature[\"assets\"] = {\n",
    "                key: asset for key, asset in feature[\"assets\"].items() if \"href\" in asset\n",
    "            }\n",
    "            removed_count = original_count - len(feature[\"assets\"])\n",
    "            if removed_count > 0:\n",
    "                item_id = feature.get(\"id\", \"unknown\")\n",
    "                # print(f\"‚ö†Ô∏è  Item {item_id}: Removed {removed_count} asset(s) with missing href\")\n",
    "\n",
    "        # Now parse the cleaned item\n",
    "        try:\n",
    "            item = Item.from_dict(feature)\n",
    "            items.append(item)\n",
    "        except Exception as e:\n",
    "            item_id = feature.get(\"id\", \"unknown\")\n",
    "            print(f\"‚ö†Ô∏è  Skipping item {item_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "print(f\"\\n‚úÖ Found {len(items)} items (after filtering).\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit Items to Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_item_exists_in_target(item_id: str, target_collection: str) -> bool:\n",
    "    \"\"\"\n",
    "    Check if a STAC item already exists in the target catalog.\n",
    "\n",
    "    Args:\n",
    "        item_id: The ID of the STAC item to check\n",
    "        target_collection: The target collection to check in\n",
    "\n",
    "    Returns:\n",
    "        True if item exists, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Try to get the specific item\n",
    "        item_url = f\"{TARGET_STAC_API_URL}/collections/{target_collection}/items/{item_id}\"\n",
    "        response = requests.get(item_url)\n",
    "\n",
    "        # If we get a 200 response, the item exists\n",
    "        return response.status_code == 200\n",
    "\n",
    "    except Exception as e:\n",
    "        # If there's any error, assume the item doesn't exist\n",
    "        # This prevents false positives that could skip valid items\n",
    "        print(f\"‚ö†Ô∏è  Error checking if item {item_id} exists: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_item_to_pipeline(item_url: str, target_collection: str) -> bool:\n",
    "    \"\"\"\n",
    "    Submit a single STAC item to the data pipeline via HTTP webhook.\n",
    "\n",
    "    Args:\n",
    "        item_url: The self-link URL of the STAC item\n",
    "        target_collection: The target collection for processing\n",
    "\n",
    "    Returns:\n",
    "        True if successful, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create payload\n",
    "        payload = {\n",
    "            \"source_url\": item_url,\n",
    "            \"collection\": target_collection,\n",
    "            \"action\": \"convert-v1-s2\",  # specify the action to use the V1 S2 trigger\n",
    "        }\n",
    "\n",
    "        # Submit via HTTP webhook endpoint\n",
    "        message = json.dumps(payload)\n",
    "        response = requests.post(\n",
    "            WEBHOOK_URL,\n",
    "            data=message,\n",
    "            headers={\"Content-Type\": \"application/json\"},\n",
    "        )\n",
    "\n",
    "        response.raise_for_status()\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error submitting item: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit all found items to the pipeline (skip items already in target catalog)\n",
    "if items:\n",
    "    print(f\"\\nüì§ Processing {len(items)} items...\\n\")\n",
    "\n",
    "    success_count = 0\n",
    "    fail_count = 0\n",
    "    skipped_count = 0\n",
    "\n",
    "    for item in items:\n",
    "        # Check if item already exists in target catalog\n",
    "        if check_item_exists_in_target(item.id, target_collection):\n",
    "            print(f\"‚è≠Ô∏è  Skipping {item.id}: Already exists in target catalog\")\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "\n",
    "        # Get the self link (canonical URL for the item)\n",
    "        item_url = next((link.href for link in item.links if link.rel == \"self\"), None)\n",
    "\n",
    "        if not item_url:\n",
    "            print(f\"‚ö†Ô∏è  Skipping {item.id}: No self link found\")\n",
    "            fail_count += 1\n",
    "            continue\n",
    "\n",
    "        # Submit to pipeline\n",
    "        if submit_item_to_pipeline(item_url, target_collection):\n",
    "            print(f\"‚úÖ Submitted: {item.id}\")\n",
    "            success_count += 1\n",
    "        else:\n",
    "            print(f\"‚ùå Failed: {item.id}\")\n",
    "            fail_count += 1\n",
    "\n",
    "    print(\"\\nüìä Summary:\")\n",
    "    print(f\"  - Successfully submitted: {success_count}\")\n",
    "    print(f\"  - Already existed (skipped): {skipped_count}\")\n",
    "    print(f\"  - Failed: {fail_count}\")\n",
    "    print(f\"  - Total processed: {len(items)}\")\n",
    "else:\n",
    "    print(\"No items to submit.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit Specific Items (Optional)\n",
    "\n",
    "If you want to submit only specific items instead of all found items, you can manually select them:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Submit only specific items by index\n",
    "# Uncomment and modify as needed\n",
    "\n",
    "# selected_indices = [0, 1, 2]  # Select first 3 items\n",
    "#\n",
    "# for idx in selected_indices:\n",
    "#     if idx < len(items):\n",
    "#         item = items[idx]\n",
    "#         item_url = next((link.href for link in item.links if link.rel == \"self\"), None)\n",
    "#\n",
    "#         if item_url:\n",
    "#             if submit_item_to_pipeline(item_url, target_collection):\n",
    "#                 print(f\"‚úÖ Submitted: {item.id}\")\n",
    "#             else:\n",
    "#                 print(f\"‚ùå Failed: {item.id}\")\n",
    "#     else:\n",
    "#         print(f\"‚ö†Ô∏è  Index {idx} out of range\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
