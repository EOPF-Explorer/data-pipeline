{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STAC Item Search and Submission to Data Pipeline\n",
    "\n",
    "This notebook allows operators to:\n",
    "\n",
    "1. Define an area of interest (AOI) and time range\n",
    "2. Search for STAC items from the EOPF STAC catalog\n",
    "3. Submit selected items to the data pipeline for processing via HTTP webhook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import requests\n",
    "from pystac import Item\n",
    "from pystac_client import Client\n",
    "\n",
    "# Try to load .env file if available\n",
    "# try:\n",
    "#     from dotenv import load_dotenv\n",
    "\n",
    "#     dotenv_path = Path(\".env\")\n",
    "#     if dotenv_path.exists():\n",
    "#         load_dotenv(dotenv_path)\n",
    "#         print(\"‚úÖ Loaded credentials from .env file\")\n",
    "#     else:\n",
    "#         print(\"‚ÑπÔ∏è  No .env file found, will prompt for credentials\")\n",
    "# except ImportError:\n",
    "#     print(\"‚ÑπÔ∏è  python-dotenv not installed, will prompt for credentials\")\n",
    "#     print(\"   Install with: pip install python-dotenv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration loaded\n"
     ]
    }
   ],
   "source": [
    "# STAC API Configuration\n",
    "STAC_API_URL = \"https://stac.core.eopf.eodc.eu/\"\n",
    "\n",
    "# Webhook Configuration\n",
    "WEBHOOK_URL = \"http://localhost:12000/samples\"\n",
    "\n",
    "print(\"‚úÖ Configuration loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Area and Time of Interest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area of Interest: [12.0, 44.4, 14.0, 45.0]\n",
      "Time Range: 2025-04-01T00:00:00Z to 2025-04-28T23:59:59Z\n"
     ]
    }
   ],
   "source": [
    "# Area of Interest (AOI) - Bounding box: [min_lon, min_lat, max_lon, max_lat]\n",
    "# Example: Rome area\n",
    "# aoi_bbox = [12.4, 41.8, 12.6, 42.0]\n",
    "# Example 2: Majorca area (2.1697998046875004%2C39.21097520599528%2C3.8177490234375004)\n",
    "# aoi_bbox = [2.16, 39.21, 3.82, 39.78]\n",
    "# Example 3: France Full\n",
    "# aoi_bbox = [-5.14, 41.33, 9.56, 51.09]\n",
    "# Example 4: Lagoon From Venice to Trieste\n",
    "aoi_bbox = [12.0, 44.4, 14.0, 45.0]\n",
    "\n",
    "# Time range\n",
    "start_date = \"2025-04-01T00:00:00Z\"\n",
    "end_date = \"2025-04-28T23:59:59Z\"\n",
    "\n",
    "print(f\"Area of Interest: {aoi_bbox}\")\n",
    "print(f\"Time Range: {start_date} to {end_date}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Browse Available Collections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìö Available Collections (12 total):\n",
      "\n",
      "  - sentinel-2-l2a\n",
      "    The Sentinel-2 Level-2A Collection 1 product provides orthorectified Surface Reflectance (Bottom-Of-...\n",
      "\n",
      "  - sentinel-3-olci-l2-lrr\n",
      "    The Sentinel-3 OLCI L2 LRR product provides land and atmospheric geophysical parameters computed for...\n",
      "\n",
      "  - sentinel-3-olci-l2-lfr\n",
      "    The Sentinel-3 OLCI L2 LFR product provides land and atmospheric geophysical parameters computed for...\n",
      "\n",
      "  - sentinel-2-l1c\n",
      "    The Sentinel-2 Level-1C product is composed of 110x110 km2 tiles (ortho-images in UTM/WGS84 projecti...\n",
      "\n",
      "  - sentinel-3-olci-l1-efr\n",
      "    The Sentinel-3 OLCI L1 EFR product provides TOA radiances at full resolution for each pixel in the i...\n",
      "\n",
      "  - sentinel-1-l1-grd\n",
      "    The Sentinel-1 Level-1 Ground Range Detected (GRD) products consist of focused SAR data that has bee...\n",
      "\n",
      "  - sentinel-3-slstr-l2-frp\n",
      "    The Sentinel-3 SLSTR Level-2 FRP product provides global (over land and water) fire radiative power.\n",
      "\n",
      "  - sentinel-1-l1-slc\n",
      "    The Sentinel-1 Level-1 Single Look Complex (SLC) products consist of focused SAR data, geo-reference...\n",
      "\n",
      "  - sentinel-3-olci-l1-err\n",
      "    The Sentinel-3 OLCI L1 ERR product provides TOA radiances at reduced resolution for each pixel in th...\n",
      "\n",
      "  - sentinel-1-l2-ocn\n",
      "    The Sentinel-1 Level-2 Ocean (OCN) products for wind, wave and currents applications may contain the...\n",
      "\n",
      "  - sentinel-3-slstr-l2-lst\n",
      "    The Sentinel-3 SLSTR Level-2 LST product provides land surface temperature.\n",
      "\n",
      "  - sentinel-3-slstr-l1-rbt\n",
      "    The Sentinel-3 SLSTR Level-1B RBT product provides radiances and brightness temperatures for each pi...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emathot/Workspace/eopf-explorer/data-pipeline/.venv/lib/python3.13/site-packages/pystac/collection.py:658: UserWarning: Collection is missing extent, setting default spatial and temporal extents\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Connect to STAC API\n",
    "catalog = Client.open(STAC_API_URL)\n",
    "\n",
    "# List available collections\n",
    "collections = list(catalog.get_collections())\n",
    "\n",
    "print(f\"\\nüìö Available Collections ({len(collections)} total):\\n\")\n",
    "for col in collections:\n",
    "    print(f\"  - {col.id}\")\n",
    "    if col.description:\n",
    "        print(\n",
    "            f\"    {col.description[:100]}...\"\n",
    "            if len(col.description) > 100\n",
    "            else f\"    {col.description}\"\n",
    "        )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Collection and Search for Items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Searching collection: sentinel-2-l1c\n",
      "üéØ Target collection for processing: sentinel-2-l1c\n"
     ]
    }
   ],
   "source": [
    "# Choose the source collection to search\n",
    "source_collection = \"sentinel-2-l1c\"  # Change this to your desired collection\n",
    "\n",
    "# Choose the target collection for processing\n",
    "target_collection = \"sentinel-2-l1c\"  # Change this to your target collection\n",
    "\n",
    "print(f\"üîç Searching collection: {source_collection}\")\n",
    "print(f\"üéØ Target collection for processing: {target_collection}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Found 34 items (after filtering).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Search for items\n",
    "search = catalog.search(\n",
    "    collections=[source_collection],\n",
    "    bbox=aoi_bbox,\n",
    "    datetime=f\"{start_date}/{end_date}\",  # Adjust as needed\n",
    "    limit=200,  # Adjust limit as needed\n",
    ")\n",
    "\n",
    "# Collect items paginated results and clean them (workaround for issue #26)\n",
    "# Use pages_as_dicts() to get raw JSON before PySTAC parsing\n",
    "items = []\n",
    "\n",
    "for page_dict in search.pages_as_dicts():\n",
    "    for feature in page_dict.get(\"features\", []):\n",
    "        # Clean assets with missing href before parsing\n",
    "        if \"assets\" in feature:\n",
    "            original_count = len(feature[\"assets\"])\n",
    "            feature[\"assets\"] = {\n",
    "                key: asset for key, asset in feature[\"assets\"].items() if \"href\" in asset\n",
    "            }\n",
    "            removed_count = original_count - len(feature[\"assets\"])\n",
    "            if removed_count > 0:\n",
    "                item_id = feature.get(\"id\", \"unknown\")\n",
    "                # print(f\"‚ö†Ô∏è  Item {item_id}: Removed {removed_count} asset(s) with missing href\")\n",
    "\n",
    "        # Now parse the cleaned item\n",
    "        try:\n",
    "            item = Item.from_dict(feature)\n",
    "            items.append(item)\n",
    "        except Exception as e:\n",
    "            item_id = feature.get(\"id\", \"unknown\")\n",
    "            print(f\"‚ö†Ô∏è  Skipping item {item_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "print(f\"\\n‚úÖ Found {len(items)} items (after filtering).\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit Items to Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_item_to_pipeline(item_url: str, target_collection: str) -> bool:\n",
    "    \"\"\"\n",
    "    Submit a single STAC item to the data pipeline via HTTP webhook.\n",
    "\n",
    "    Args:\n",
    "        item_url: The self-link URL of the STAC item\n",
    "        target_collection: The target collection for processing\n",
    "\n",
    "    Returns:\n",
    "        True if successful, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create payload\n",
    "        payload = {\n",
    "            \"source_url\": item_url,\n",
    "            \"collection\": target_collection,\n",
    "            \"action\": \"convert-v1-s2\",  # specify the action to use the V1 S2 trigger\n",
    "        }\n",
    "\n",
    "        # Submit via HTTP webhook endpoint\n",
    "        message = json.dumps(payload)\n",
    "        response = requests.post(\n",
    "            WEBHOOK_URL,\n",
    "            data=message,\n",
    "            headers={\"Content-Type\": \"application/json\"},\n",
    "        )\n",
    "\n",
    "        response.raise_for_status()\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error submitting item: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì§ Submitting 34 items to pipeline...\n",
      "\n",
      "‚úÖ Submitted: S2B_MSIL1C_20250427T100559_N0511_R022_T33TUK_20250427T123603\n",
      "‚úÖ Submitted: S2B_MSIL1C_20250427T100559_N0511_R022_T32TQR_20250427T123603\n",
      "‚úÖ Submitted: S2B_MSIL1C_20250427T100559_N0511_R022_T32TQQ_20250427T123603\n",
      "‚úÖ Submitted: S2A_MSIL1C_20250424T101041_N0511_R022_T33TUK_20250424T153018\n",
      "‚úÖ Submitted: S2A_MSIL1C_20250424T101041_N0511_R022_T32TQR_20250424T153018\n",
      "‚úÖ Submitted: S2A_MSIL1C_20250424T101041_N0511_R022_T32TQQ_20250424T170815\n",
      "‚úÖ Submitted: S2A_MSIL1C_20250424T101041_N0511_R022_T32TQQ_20250424T153018\n",
      "‚úÖ Submitted: S2B_MSIL1C_20250424T100029_N0511_R122_T33TVK_20250424T122548\n",
      "‚úÖ Submitted: S2B_MSIL1C_20250424T100029_N0511_R122_T33TUK_20250424T122548\n",
      "‚úÖ Submitted: S2B_MSIL1C_20250424T100029_N0511_R122_T32TQR_20250424T122548\n",
      "‚úÖ Submitted: S2B_MSIL1C_20250424T100029_N0511_R122_T32TQQ_20250424T122548\n",
      "‚úÖ Submitted: S2C_MSIL1C_20250422T101051_N0511_R022_T33TUK_20250422T140109\n",
      "‚úÖ Submitted: S2C_MSIL1C_20250422T101051_N0511_R022_T32TQR_20250422T140109\n",
      "‚úÖ Submitted: S2C_MSIL1C_20250422T101051_N0511_R022_T32TQQ_20250422T140109\n",
      "‚úÖ Submitted: S2C_MSIL1C_20250419T100051_N0511_R122_T33TVK_20250419T134436\n",
      "‚úÖ Submitted: S2C_MSIL1C_20250419T100051_N0511_R122_T33TUK_20250419T134436\n",
      "‚úÖ Submitted: S2C_MSIL1C_20250419T100051_N0511_R122_T32TQR_20250419T134436\n",
      "‚úÖ Submitted: S2C_MSIL1C_20250419T100051_N0511_R122_T32TQQ_20250419T134436\n",
      "‚úÖ Submitted: S2B_MSIL1C_20250417T100559_N0511_R022_T33TUK_20250417T123703\n",
      "‚úÖ Submitted: S2B_MSIL1C_20250417T100559_N0511_R022_T32TQR_20250417T123703\n",
      "‚úÖ Submitted: S2B_MSIL1C_20250417T100559_N0511_R022_T32TQQ_20250417T123703\n",
      "‚úÖ Submitted: S2A_MSIL1C_20250414T100701_N0511_R022_T33TUK_20250414T153115\n",
      "‚úÖ Submitted: S2A_MSIL1C_20250414T100701_N0511_R022_T32TQR_20250414T153115\n",
      "‚úÖ Submitted: S2A_MSIL1C_20250414T100701_N0511_R022_T32TQQ_20250414T153115\n",
      "‚úÖ Submitted: S2B_MSIL1C_20250414T100029_N0511_R122_T33TVK_20250414T122616\n",
      "‚úÖ Submitted: S2B_MSIL1C_20250414T100029_N0511_R122_T33TUK_20250414T122616\n",
      "‚úÖ Submitted: S2B_MSIL1C_20250414T100029_N0511_R122_T32TQR_20250414T122616\n",
      "‚úÖ Submitted: S2B_MSIL1C_20250414T100029_N0511_R122_T32TQQ_20250414T122616\n",
      "‚úÖ Submitted: S2C_MSIL1C_20250412T101041_N0511_R022_T33TUK_20250412T134850\n",
      "‚úÖ Submitted: S2A_MSIL1C_20250411T100041_N0511_R122_T33TUK_20250411T152338\n",
      "‚úÖ Submitted: S2A_MSIL1C_20250411T100041_N0511_R122_T32TQR_20250411T152338\n",
      "‚úÖ Submitted: S2C_MSIL1C_20250409T100051_N0511_R122_T33TUK_20250409T134445\n",
      "‚úÖ Submitted: S2C_MSIL1C_20250409T100051_N0511_R122_T32TQR_20250409T134445\n",
      "‚úÖ Submitted: S2C_MSIL1C_20250409T100051_N0511_R122_T32TQQ_20250409T134445\n",
      "\n",
      "üìä Summary:\n",
      "  - Successfully submitted: 34\n",
      "  - Failed: 0\n",
      "  - Total: 34\n"
     ]
    }
   ],
   "source": [
    "# Submit all found items to the pipeline\n",
    "if items:\n",
    "    print(f\"\\nüì§ Submitting {len(items)} items to pipeline...\\n\")\n",
    "\n",
    "    success_count = 0\n",
    "    fail_count = 0\n",
    "\n",
    "    for item in items:\n",
    "        # Get the self link (canonical URL for the item)\n",
    "        item_url = next((link.href for link in item.links if link.rel == \"self\"), None)\n",
    "\n",
    "        if not item_url:\n",
    "            print(f\"‚ö†Ô∏è  Skipping {item.id}: No self link found\")\n",
    "            fail_count += 1\n",
    "            continue\n",
    "\n",
    "        # Submit to pipeline\n",
    "        if submit_item_to_pipeline(item_url, target_collection):\n",
    "            print(f\"‚úÖ Submitted: {item.id}\")\n",
    "            success_count += 1\n",
    "        else:\n",
    "            print(f\"‚ùå Failed: {item.id}\")\n",
    "            fail_count += 1\n",
    "\n",
    "    print(\"\\nüìä Summary:\")\n",
    "    print(f\"  - Successfully submitted: {success_count}\")\n",
    "    print(f\"  - Failed: {fail_count}\")\n",
    "    print(f\"  - Total: {len(items)}\")\n",
    "else:\n",
    "    print(\"No items to submit.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit Specific Items (Optional)\n",
    "\n",
    "If you want to submit only specific items instead of all found items, you can manually select them:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Submit only specific items by index\n",
    "# Uncomment and modify as needed\n",
    "\n",
    "# selected_indices = [0, 1, 2]  # Select first 3 items\n",
    "#\n",
    "# for idx in selected_indices:\n",
    "#     if idx < len(items):\n",
    "#         item = items[idx]\n",
    "#         item_url = next((link.href for link in item.links if link.rel == \"self\"), None)\n",
    "#\n",
    "#         if item_url:\n",
    "#             if submit_item_to_pipeline(item_url, target_collection):\n",
    "#                 print(f\"‚úÖ Submitted: {item.id}\")\n",
    "#             else:\n",
    "#                 print(f\"‚ùå Failed: {item.id}\")\n",
    "#     else:\n",
    "#         print(f\"‚ö†Ô∏è  Index {idx} out of range\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
